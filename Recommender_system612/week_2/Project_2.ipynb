{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHlVN5StW7Z6",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The goal of this assignment is for you to try out different ways of implementing and configuring a recommender, and to evaluate your different approaches.\n",
        "\n",
        "In this notebook, I will demonestrate two different methods for recommender system. \n",
        "\n",
        "1. **Collaborative Filtering**: This method makes automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on a set of items, A is more likely to have B's opinion for a given item than that of a randomly chosen person.\n",
        "\n",
        "2. **Content-Based Filtering**: This method uses only information about the description and attributes of the items users has previously consumed to model user's preferences. In other words, these algorithms try to recommend items that are similar to those that a user liked in the past (or is examining in the present). In particular, various candidate items are compared with items previously rated by the user and the best-matching items are recommended.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p5D_OD5cSaV",
        "colab_type": "text"
      },
      "source": [
        "In this notebook, I will use a dataset shared on Kaggle Datasets: Articles Sharing and Reading from CI&T Deskdrop.\n",
        "I will demonstrate how to implement Collaborative Filtering and Content-Based Filtering methods in Python, for the task of providing personalized recommendations to the users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNa2G_RFXriw",
        "colab_type": "text"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eafodDzZS97K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "import sklearn\n",
        "from nltk.corpus import stopwords\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5SJ0o4dc2Tg",
        "colab_type": "text"
      },
      "source": [
        "In this section, I loaded the Deskdrop dataset, which contains a real sample of 12 months logs (Mar. 2016 - Feb. 2017) from CI&T's Internal Communication platform (DeskDrop. It contains about 73k logged users interactions on more than 3k public articles shared in the platform. It is composed of two CSV files:\n",
        "\n",
        "1. shared_articles.csv\n",
        "2. users_interactions.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eV7vYFudNqq",
        "colab_type": "text"
      },
      "source": [
        "## Shared_articles.csv\n",
        "\n",
        "Contains information about the articles shared in the platform. Each article has its sharing date (timestamp), the original url, title, content in plain text, the article' lang (Portuguese: pt or English: en) and information about the user who shared the article (author).\n",
        "\n",
        "There are two possible event types at a given timestamp:\n",
        "\n",
        "* **CONTENT SHARED**: The article was shared in the platform and is available for users.\n",
        "\n",
        "* **CONTENT REMOVED**: The article was removed from the platform and not available for further recommendation.\n",
        "\n",
        "\n",
        "For simplicity, I will only consider the **\"CONTENT SHARED\"** event type, assuming (naively) that all articles were available during the whole one year period. \n",
        "\n",
        "For a more precise evaluation (and higher accuracy), only articles that were available at a given time should be recommended."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKSrvDmQES1N",
        "colab_type": "code",
        "outputId": "ee2cb58c-9735-4ca5-b88f-bf5bb4952f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "path = '/content/drive/My Drive/2234_3774_bundle_archive/shared_articles.csv'\n",
        "articles_df = pd.read_csv(path)\n",
        "articles_df.head()\n",
        "articles_df = articles_df[articles_df['eventType'] == 'CONTENT SHARED']\n",
        "articles_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>eventType</th>\n",
              "      <th>contentId</th>\n",
              "      <th>authorPersonId</th>\n",
              "      <th>authorSessionId</th>\n",
              "      <th>authorUserAgent</th>\n",
              "      <th>authorRegion</th>\n",
              "      <th>authorCountry</th>\n",
              "      <th>contentType</th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1459193988</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-4110354420726924665</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>http://www.nytimes.com/2016/03/28/business/dea...</td>\n",
              "      <td>Ethereum, a Virtual Currency, Enables Transact...</td>\n",
              "      <td>All of this work is still very early. The firs...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1459194146</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-7292285110016212249</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>http://cointelegraph.com/news/bitcoin-future-w...</td>\n",
              "      <td>Bitcoin Future: When GBPcoin of Branson Wins O...</td>\n",
              "      <td>The alarm clock wakes me at 8:00 with stream o...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1459194474</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-6151852268067518688</td>\n",
              "      <td>3891637997717104548</td>\n",
              "      <td>-1457532940883382585</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>https://cloudplatform.googleblog.com/2016/03/G...</td>\n",
              "      <td>Google Data Center 360Â° Tour</td>\n",
              "      <td>We're excited to share the Google Data Center ...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1459194497</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>2448026894306402386</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>https://bitcoinmagazine.com/articles/ibm-wants...</td>\n",
              "      <td>IBM Wants to \"Evolve the Internet\" With Blockc...</td>\n",
              "      <td>The Aite Group projects the blockchain market ...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1459194522</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-2826566343807132236</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>http://www.coindesk.com/ieee-blockchain-oxford...</td>\n",
              "      <td>IEEE to Talk Blockchain at Cloud Computing Oxf...</td>\n",
              "      <td>One of the largest and oldest organizations fo...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp  ... lang\n",
              "1  1459193988  ...   en\n",
              "2  1459194146  ...   en\n",
              "3  1459194474  ...   en\n",
              "4  1459194497  ...   en\n",
              "5  1459194522  ...   en\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVIICPSGi82f",
        "colab_type": "text"
      },
      "source": [
        "## Users_interactions.csv\n",
        "\n",
        "Contains logs of user interactions on **shared articles**. It can be joined to **articles_shared.csv** by ***contentId*** column.\n",
        "\n",
        "The eventType values are:\n",
        "\n",
        "* **VIEW**: The user has opened the article.\n",
        "* **LIKE**: The user has liked the article.\n",
        "* **COMMENT CREATED**: The user created a comment in the article.\n",
        "* **FOLLOW**: The user chose to be notified on any new comment in the article.\n",
        "* **BOOKMARK**: The user has bookmarked the article for easy return in the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoEeoczJjXo6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "0983af79-b727-4856-f647-841c19698404"
      },
      "source": [
        "path = '/content/drive/My Drive/2234_3774_bundle_archive/users_interactions.csv'\n",
        "interactions_df = pd.read_csv(path)\n",
        "interactions_df.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>eventType</th>\n",
              "      <th>contentId</th>\n",
              "      <th>personId</th>\n",
              "      <th>sessionId</th>\n",
              "      <th>userAgent</th>\n",
              "      <th>userRegion</th>\n",
              "      <th>userCountry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1465413032</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>-3499919498720038879</td>\n",
              "      <td>-8845298781299428018</td>\n",
              "      <td>1264196770339959068</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1465412560</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>8890720798209849691</td>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>3621737643587579081</td>\n",
              "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...</td>\n",
              "      <td>NY</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1465416190</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>310515487419366995</td>\n",
              "      <td>-1130272294246983140</td>\n",
              "      <td>2631864456530402479</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1465413895</td>\n",
              "      <td>FOLLOW</td>\n",
              "      <td>310515487419366995</td>\n",
              "      <td>344280948527967603</td>\n",
              "      <td>-3167637573980064150</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465412290</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>-7820640624231356730</td>\n",
              "      <td>-445337111692715325</td>\n",
              "      <td>5611481178424124714</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp eventType  ...  userRegion  userCountry\n",
              "0  1465413032      VIEW  ...         NaN          NaN\n",
              "1  1465412560      VIEW  ...          NY           US\n",
              "2  1465416190      VIEW  ...         NaN          NaN\n",
              "3  1465413895    FOLLOW  ...         NaN          NaN\n",
              "4  1465412290      VIEW  ...         NaN          NaN\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr53AboajuHN",
        "colab_type": "text"
      },
      "source": [
        "# Data joining\n",
        "\n",
        "As there are different interactions types, we associate them with a weight or strength, assuming that, for example, a comment in an article indicates a higher interest of the user on the item than a like, or than a simple view."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSsW8VrHkLL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "21343c1f-de27-42b2-ae9d-39cc316bfe28"
      },
      "source": [
        "event_type_weight = {\n",
        "    'VIEW': 1.0,\n",
        "    'LIKE': 2.0,\n",
        "    'BOOKMARK': 2.5,\n",
        "    'FOLLOW': 3.0,\n",
        "    'COMMENT CREATED': 4.0\n",
        "}\n",
        "\n",
        "interactions_df['eventWeight'] = userinter_df['eventType'].apply(lambda x:event_type_weight[x])\n",
        "interactions_df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>eventType</th>\n",
              "      <th>contentId</th>\n",
              "      <th>personId</th>\n",
              "      <th>sessionId</th>\n",
              "      <th>userAgent</th>\n",
              "      <th>userRegion</th>\n",
              "      <th>userCountry</th>\n",
              "      <th>eventWeight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1465413032</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>-3499919498720038879</td>\n",
              "      <td>-8845298781299428018</td>\n",
              "      <td>1264196770339959068</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1465412560</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>8890720798209849691</td>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>3621737643587579081</td>\n",
              "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...</td>\n",
              "      <td>NY</td>\n",
              "      <td>US</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1465416190</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>310515487419366995</td>\n",
              "      <td>-1130272294246983140</td>\n",
              "      <td>2631864456530402479</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1465413895</td>\n",
              "      <td>FOLLOW</td>\n",
              "      <td>310515487419366995</td>\n",
              "      <td>344280948527967603</td>\n",
              "      <td>-3167637573980064150</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465412290</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>-7820640624231356730</td>\n",
              "      <td>-445337111692715325</td>\n",
              "      <td>5611481178424124714</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp eventType  ...  userCountry  eventWeight\n",
              "0  1465413032      VIEW  ...          NaN          1.0\n",
              "1  1465412560      VIEW  ...           US          1.0\n",
              "2  1465416190      VIEW  ...          NaN          1.0\n",
              "3  1465413895    FOLLOW  ...          NaN          3.0\n",
              "4  1465412290      VIEW  ...          NaN          1.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXLglAp9m7wJ",
        "colab_type": "text"
      },
      "source": [
        "I will keep only users with at least 5 interactions to avoid the **user cold-start** issue.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko2LXUfFnW2r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "28c33ab3-5157-4a0e-aa0f-3a6573538b33"
      },
      "source": [
        "users_interactions_count_df = interactions_df.groupby(['personId', 'contentId']).size().groupby('personId').size()\n",
        "print('Number of users: ', len(users_interactions_count_df))\n",
        "\n",
        "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['personId']]\n",
        "print('Number of users with min. 5 interactions: ', len(users_with_enough_interactions_df))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users:  1895\n",
            "Number of users with min. 5 interactions:  1140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS6vBWwLrK64",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8d791481-3f05-4906-ab88-df0cdf3782ab"
      },
      "source": [
        "print('Number of total users interactions: ', len(interactions_df))\n",
        "\n",
        "# merging two tables \n",
        "interactions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df, \n",
        "               how = 'right',\n",
        "               left_on = 'personId',\n",
        "               right_on = 'personId')\n",
        "print('Number of interactions from users with min. 5 interactions: ', len(interactions_from_selected_users_df))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of total users interactions:  72312\n",
            "Number of interactions from users with min. 5 interactions:  69868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-M0ZcQ7sBfn",
        "colab_type": "text"
      },
      "source": [
        "to model the user interest on a given article, we aggregate all the interactions the user has performed in an item by a weighted sum of interaction type strength and apply a log transformation to smooth the distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSn7ByXMsQU0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d81877f7-c5b6-40ee-b586-64535d514341"
      },
      "source": [
        "def smooth_user_preference(x):\n",
        "    return math.log(1+x, 2)\n",
        "    \n",
        "interactions_full_df = interactions_from_selected_users_df \\\n",
        "                    .groupby(['personId', 'contentId'])['eventWeight'].sum() \\\n",
        "                    .apply(smooth_user_preference).reset_index()\n",
        "\n",
        "print('Number of unique user per item interaction: ', len(interactions_full_df))\n",
        "interactions_full_df.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique user per item interaction:  39106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personId</th>\n",
              "      <th>contentId</th>\n",
              "      <th>eventWeight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-8949113594875411859</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-8377626164558006982</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-8208801367848627943</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-8187220755213888616</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-7423191370472335463</td>\n",
              "      <td>3.169925</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              personId            contentId  eventWeight\n",
              "0 -9223121837663643404 -8949113594875411859     1.000000\n",
              "1 -9223121837663643404 -8377626164558006982     1.000000\n",
              "2 -9223121837663643404 -8208801367848627943     1.000000\n",
              "3 -9223121837663643404 -8187220755213888616     1.000000\n",
              "4 -9223121837663643404 -7423191370472335463     3.169925"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe_0TB9ftFJs",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "One key aspect of evaluation is to ensure that the trained model generalizes for data it was not trained on, using **Cross-validation** techniques. I am using a simple cross-validation approach named **holdout**, in which a random data sample (20% in this case) are kept aside in the training process, and exclusively used for evaluation. All evaluation metrics reported are computed using the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI99a0L_u51i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e221aaa3-f394-4914-8a07-dfe45fee7e73"
      },
      "source": [
        "interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n",
        "                                   stratify=interactions_full_df['personId'], \n",
        "                                   test_size=0.20,\n",
        "                                   random_state=42)\n",
        "print('Number of interactions on the train dataset: ', len(interactions_train_df))\n",
        "print('Number of interactions on the test dataset: ', len(interactions_test_df))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of interactions on the train dataset:  31284\n",
            "Number of interactions on the test dataset:  7822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOSjWnkTvgqK",
        "colab_type": "text"
      },
      "source": [
        "I chose to work with **Top-N accuracy metrics**, which evaluates the accuracy of the top recommendations provided to a user, comparing to the items the user has actually interacted in test set.\n",
        "\n",
        "This evaluation method works as follows:\n",
        "\n",
        "* For each user\n",
        "\n",
        "> * For each item the user has interacted in test set\n",
        "> > * Sample 100 other items the user has never interacted.\n",
        "Ps. Here I naively assume those non interacted items are not relevant to the user, which might not be true, as the user may simply not be aware of those not interacted items. \n",
        "> > * Ask the recommender model to produce a ranked list of recommended items, from a set composed one interacted item and the 100 non-interacted (\"non-relevant!) items\n",
        "> > * Compute the Top-N accuracy metrics for this user and interacted item from the recommendations ranked list\n",
        "* \n",
        "Aggregate the global Top-N accuracy metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iRmJJKzvgE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Indexing by personId to speed up the searches during evaluation\n",
        "interactions_full_indexed_df = interactions_full_df.set_index('personId')\n",
        "interactions_train_indexed_df = interactions_train_df.set_index('personId')\n",
        "interactions_test_indexed_df = interactions_test_df.set_index('personId')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm-ZQ4DQwzAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_items_interacted(person_id, interactions_df):\n",
        "    # Get the user's data and merge in the movie information.\n",
        "    interacted_items = interactions_df.loc[person_id]['contentId']\n",
        "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVdZXGL9xXLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Top-N accuracy metrics consts\n",
        "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
        "\n",
        "class ModelEvaluator:\n",
        "\n",
        "\n",
        "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n",
        "        interacted_items = get_items_interacted(person_id, interactions_full_indexed_df)\n",
        "        all_items = set(articles_df['contentId'])\n",
        "        non_interacted_items = all_items - interacted_items\n",
        "\n",
        "        random.seed(seed)\n",
        "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
        "        return set(non_interacted_items_sample)\n",
        "\n",
        "    def _verify_hit_top_n(self, item_id, recommended_items, topn):        \n",
        "            try:\n",
        "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
        "            except:\n",
        "                index = -1\n",
        "            hit = int(index in range(0, topn))\n",
        "            return hit, index\n",
        "\n",
        "    def evaluate_model_for_user(self, model, person_id):\n",
        "        #Getting the items in test set\n",
        "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
        "        if type(interacted_values_testset['contentId']) == pd.Series:\n",
        "            person_interacted_items_testset = set(interacted_values_testset['contentId'])\n",
        "        else:\n",
        "            person_interacted_items_testset = set([int(interacted_values_testset['contentId'])])  \n",
        "        interacted_items_count_testset = len(person_interacted_items_testset) \n",
        "\n",
        "\n",
        "        #Getting a ranked recommendation list from a model for a given user\n",
        "        person_recs_df = model.recommend_items(person_id, \n",
        "                                               items_to_ignore=get_items_interacted(person_id, \n",
        "                                                                                    interactions_train_indexed_df), \n",
        "                                               topn=10000000000)\n",
        "        hits_at_5_count = 0\n",
        "        hits_at_10_count = 0\n",
        "        #For each item the user has interacted in test set\n",
        "        for item_id in person_interacted_items_testset:\n",
        "            #Getting a random sample (100) items the user has not interacted \n",
        "            #(to represent items that are assumed to be no relevant to the user)\n",
        "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, \n",
        "                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n",
        "                                                                          seed=item_id%(2**32))\n",
        "\n",
        "            #Combining the current interacted item with the 100 random items\n",
        "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
        "\n",
        "            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
        "            valid_recs_df = person_recs_df[person_recs_df['contentId'].isin(items_to_filter_recs)]                    \n",
        "            valid_recs = valid_recs_df['contentId'].values\n",
        "            #Verifying if the current interacted item is among the Top-N recommended items\n",
        "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
        "            hits_at_5_count += hit_at_5\n",
        "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
        "            hits_at_10_count += hit_at_10\n",
        "\n",
        "        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n",
        "        #when mixed with a set of non-relevant items\n",
        "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
        "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
        "        person_metrics = {'hits@5_count':hits_at_5_count, \n",
        "                  'hits@10_count':hits_at_10_count, \n",
        "                  'interacted_count': interacted_items_count_testset,\n",
        "                  'recall@5': recall_at_5,\n",
        "                  'recall@10': recall_at_10}\n",
        "        return person_metrics\n",
        "\n",
        "    def evaluate_model(self, model):\n",
        "        #print('Running evaluation for users')\n",
        "        people_metrics = []\n",
        "        for idx, person_id in enumerate(list(interactions_test_indexed_df.index.unique().values)):\n",
        "            #if idx % 100 == 0 and idx > 0:\n",
        "            #    print('%d users processed' % idx)\n",
        "            person_metrics = self.evaluate_model_for_user(model, person_id)  \n",
        "            person_metrics['_person_id'] = person_id\n",
        "            people_metrics.append(person_metrics)\n",
        "        print('%d users processed' % idx)\n",
        "\n",
        "        detailed_results_df = pd.DataFrame(people_metrics) \\\n",
        "                            .sort_values('interacted_count', ascending=False)\n",
        "        \n",
        "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "        \n",
        "        global_metrics = {'modelName': model.get_model_name(),\n",
        "                          'recall@5': global_recall_at_5,\n",
        "                          'recall@10': global_recall_at_10}    \n",
        "        return global_metrics, detailed_results_df\n",
        "    \n",
        "model_evaluator = ModelEvaluator()    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y_MgtSd0maW",
        "colab_type": "text"
      },
      "source": [
        "# Popularity model\n",
        "\n",
        "A common (and usually hard-to-beat) baseline approach is the Popularity model. This model is not actually personalized - it simply recommends to a user the most popular items that the user has not previously consumed. As the popularity accounts for the \"wisdom of the crowds\", it usually provides good recommendations, generally interesting for most people.\n",
        "Ps. The main objective of a recommender system is to leverage the long-tail items to the users with very specific interests, which goes far beyond this simple technique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGgd4MRt0KZT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "cdbb4b70-02c7-41cb-b09a-2e679b6bfd89"
      },
      "source": [
        "#Computes the most popular items\n",
        "item_popularity_df = interactions_full_df.groupby('contentId')['eventWeight'].sum().sort_values(ascending=False).reset_index()\n",
        "item_popularity_df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contentId</th>\n",
              "      <th>eventWeight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-4029704725707465084</td>\n",
              "      <td>307.733799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-6783772548752091658</td>\n",
              "      <td>233.762157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-133139342397538859</td>\n",
              "      <td>228.024567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-8208801367848627943</td>\n",
              "      <td>197.107608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-6843047699859121724</td>\n",
              "      <td>193.825208</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             contentId  eventWeight\n",
              "0 -4029704725707465084   307.733799\n",
              "1 -6783772548752091658   233.762157\n",
              "2  -133139342397538859   228.024567\n",
              "3 -8208801367848627943   197.107608\n",
              "4 -6843047699859121724   193.825208"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goug3ofk0_v3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PopularityRecommender:\n",
        "    \n",
        "    MODEL_NAME = 'Popularity'\n",
        "    \n",
        "    def __init__(self, popularity_df, items_df=None):\n",
        "        self.popularity_df = popularity_df\n",
        "        self.items_df = items_df\n",
        "        \n",
        "    def get_model_name(self):\n",
        "        return self.MODEL_NAME\n",
        "        \n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
        "        # Recommend the more popular items that the user hasn't seen yet.\n",
        "        recommendations_df = self.popularity_df[~self.popularity_df['contentId'].isin(items_to_ignore)] \\\n",
        "                               .sort_values('eventWeight', ascending = False) \\\n",
        "                               .head(topn)\n",
        "\n",
        "        if verbose:\n",
        "            if self.items_df is None:\n",
        "                raise Exception('\"items_df\" is required in verbose mode')\n",
        "\n",
        "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
        "                                                          left_on = 'contentId', \n",
        "                                                          right_on = 'contentId')[['eventWeight', 'contentId', 'title', 'url', 'lang']]\n",
        "\n",
        "\n",
        "        return recommendations_df\n",
        "    \n",
        "popularity_model = PopularityRecommender(item_popularity_df, articles_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtzeRdgk1O2t",
        "colab_type": "text"
      },
      "source": [
        "It achieved the **Recall@5** of **0.2417**, which means that about **24%** of interacted items in test set were ranked by Popularity model among the top-5 items (from lists with 100 random items). And **Recall@10** was even higher **(37%)**, as expected.\n",
        "It might be surprising to you that usually Popularity models could perform so well!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p9TsFSm1Y8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c7444c2f-d7d3-4ab6-98b8-80aa1be1163c"
      },
      "source": [
        "print('Evaluating Popularity recommendation model...')\n",
        "pop_global_metrics, pop_detailed_results_df = model_evaluator.evaluate_model(popularity_model)\n",
        "print('\\nGlobal metrics:\\n%s' % pop_global_metrics)\n",
        "pop_detailed_results_df.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating Popularity recommendation model...\n",
            "1139 users processed\n",
            "\n",
            "Global metrics:\n",
            "{'modelName': 'Popularity', 'recall@5': 0.2417540271030427, 'recall@10': 0.37292252620813093}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hits@5_count</th>\n",
              "      <th>hits@10_count</th>\n",
              "      <th>interacted_count</th>\n",
              "      <th>recall@5</th>\n",
              "      <th>recall@10</th>\n",
              "      <th>_person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>28</td>\n",
              "      <td>50</td>\n",
              "      <td>192</td>\n",
              "      <td>0.145833</td>\n",
              "      <td>0.260417</td>\n",
              "      <td>3609194402293569455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>134</td>\n",
              "      <td>0.089552</td>\n",
              "      <td>0.186567</td>\n",
              "      <td>-2626634673110551643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "      <td>130</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.176923</td>\n",
              "      <td>-1032019229384696495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>117</td>\n",
              "      <td>0.042735</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>-1443636648652872475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>25</td>\n",
              "      <td>40</td>\n",
              "      <td>88</td>\n",
              "      <td>0.284091</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>-2979881261169775358</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    hits@5_count  hits@10_count  ...  recall@10           _person_id\n",
              "76            28             50  ...   0.260417  3609194402293569455\n",
              "17            12             25  ...   0.186567 -2626634673110551643\n",
              "16            13             23  ...   0.176923 -1032019229384696495\n",
              "10             5              9  ...   0.076923 -1443636648652872475\n",
              "82            25             40  ...   0.454545 -2979881261169775358\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGM4UdnY2pK7",
        "colab_type": "text"
      },
      "source": [
        "# Content-Based Filtering Model\n",
        "\n",
        "Content-based filtering approaches leverage description or attributes from items the user has interacted to recommend similar items. It depends only on the user previous choices, making this method robust to avoid the cold-start problem. For textual items, like articles, news and books, it is simple to use the raw text to build item profiles and user profiles.\n",
        "Here we are using a very popular technique in information retrieval (search engines) named TF-IDF. This technique converts unstructured text into a vector structure, where each word is represented by a position in the vector, and the value measures how relevant a given word is for an article. As all items will be represented in the same Vector Space Model, it is to compute similarity between articles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUgd36bt24qI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c1608140-c4f5-4132-c501-6be1605c0bad"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "#Ignoring stopwords (words with no semantics) from English and Portuguese (as we have a corpus with mixed languages)\n",
        "stopwords_list = stopwords.words('english') + stopwords.words('portuguese')\n",
        "\n",
        "#Trains a model whose vectors size is 5000, composed by the main unigrams and bigrams found in the corpus, ignoring stopwords\n",
        "vectorizer = TfidfVectorizer(analyzer='word',\n",
        "                     ngram_range=(1, 2),\n",
        "                     min_df=0.003,\n",
        "                     max_df=0.5,\n",
        "                     max_features=5000,\n",
        "                     stop_words=stopwords_list)\n",
        "\n",
        "item_ids = articles_df['contentId'].tolist()\n",
        "tfidf_matrix = vectorizer.fit_transform(articles_df['title'] + \"\" + articles_df['text'])\n",
        "tfidf_feature_names = vectorizer.get_feature_names()\n",
        "tfidf_matrix"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3047x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 638928 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFEJrupa4Bgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_item_profile(item_id):\n",
        "    idx = item_ids.index(item_id)\n",
        "    item_profile = tfidf_matrix[idx:idx+1]\n",
        "    return item_profile\n",
        "\n",
        "def get_item_profiles(ids):\n",
        "    item_profiles_list = [get_item_profile(x) for x in ids]\n",
        "    item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
        "    return item_profiles\n",
        "\n",
        "def build_users_profile(person_id, interactions_indexed_df):\n",
        "    interactions_person_df = interactions_indexed_df.loc[person_id]\n",
        "    user_item_profiles = get_item_profiles(interactions_person_df['contentId'])\n",
        "    \n",
        "    user_item_strengths = np.array(interactions_person_df['eventWeight']).reshape(-1,1)\n",
        "    #Weighted average of item profiles by the interactions strength\n",
        "    user_item_strengths_weighted_avg = np.sum(user_item_profiles.multiply(user_item_strengths), axis=0) / np.sum(user_item_strengths)\n",
        "    user_profile_norm = sklearn.preprocessing.normalize(user_item_strengths_weighted_avg)\n",
        "    return user_profile_norm\n",
        "\n",
        "def build_users_profiles(): \n",
        "    interactions_indexed_df = interactions_train_df[interactions_train_df['contentId'] \\\n",
        "                                                   .isin(articles_df['contentId'])].set_index('personId')\n",
        "    user_profiles = {}\n",
        "    for person_id in interactions_indexed_df.index.unique():\n",
        "        user_profiles[person_id] = build_users_profile(person_id, interactions_indexed_df)\n",
        "    return user_profiles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "709RkbFt4F3W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8441592d-405f-48be-a2c1-1906e273f5fe"
      },
      "source": [
        "user_profiles = build_users_profiles()\n",
        "len(user_profiles)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HklE2PsF4UyR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "outputId": "4e01f816-f945-4da0-efd3-3de4e679fa4c"
      },
      "source": [
        "myprofile = user_profiles[-1479311724257856983]\n",
        "print(myprofile.shape)\n",
        "pd.DataFrame(sorted(zip(tfidf_feature_names, \n",
        "                        user_profiles[-1479311724257856983].flatten().tolist()), key=lambda x: -x[1])[:20],\n",
        "             columns=['token', 'relevance'])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 5000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>learning</td>\n",
              "      <td>0.298732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>machine learning</td>\n",
              "      <td>0.245992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>machine</td>\n",
              "      <td>0.237843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>google</td>\n",
              "      <td>0.202839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data</td>\n",
              "      <td>0.169776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ai</td>\n",
              "      <td>0.156203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>algorithms</td>\n",
              "      <td>0.115666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>like</td>\n",
              "      <td>0.097744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>language</td>\n",
              "      <td>0.087609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>people</td>\n",
              "      <td>0.082024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>deep</td>\n",
              "      <td>0.081542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>deep learning</td>\n",
              "      <td>0.080979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>research</td>\n",
              "      <td>0.076020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>algorithm</td>\n",
              "      <td>0.074905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>apple</td>\n",
              "      <td>0.074050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>intelligence</td>\n",
              "      <td>0.072663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>use</td>\n",
              "      <td>0.072597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>human</td>\n",
              "      <td>0.072494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>models</td>\n",
              "      <td>0.072388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>artificial</td>\n",
              "      <td>0.072062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               token  relevance\n",
              "0           learning   0.298732\n",
              "1   machine learning   0.245992\n",
              "2            machine   0.237843\n",
              "3             google   0.202839\n",
              "4               data   0.169776\n",
              "5                 ai   0.156203\n",
              "6         algorithms   0.115666\n",
              "7               like   0.097744\n",
              "8           language   0.087609\n",
              "9             people   0.082024\n",
              "10              deep   0.081542\n",
              "11     deep learning   0.080979\n",
              "12          research   0.076020\n",
              "13         algorithm   0.074905\n",
              "14             apple   0.074050\n",
              "15      intelligence   0.072663\n",
              "16               use   0.072597\n",
              "17             human   0.072494\n",
              "18            models   0.072388\n",
              "19        artificial   0.072062"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SG6Tcp-4sgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ContentBasedRecommender:\n",
        "    \n",
        "    MODEL_NAME = 'Content-Based'\n",
        "    \n",
        "    def __init__(self, items_df=None):\n",
        "        self.item_ids = item_ids\n",
        "        self.items_df = items_df\n",
        "        \n",
        "    def get_model_name(self):\n",
        "        return self.MODEL_NAME\n",
        "        \n",
        "    def _get_similar_items_to_user_profile(self, person_id, topn=1000):\n",
        "        #Computes the cosine similarity between the user profile and all item profiles\n",
        "        cosine_similarities = cosine_similarity(user_profiles[person_id], tfidf_matrix)\n",
        "        #Gets the top similar items\n",
        "        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n",
        "        #Sort the similar items by similarity\n",
        "        similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
        "        return similar_items\n",
        "        \n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
        "        similar_items = self._get_similar_items_to_user_profile(user_id)\n",
        "        #Ignores items the user has already interacted\n",
        "        similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\n",
        "        \n",
        "        recommendations_df = pd.DataFrame(similar_items_filtered, columns=['contentId', 'recStrength']) \\\n",
        "                                    .head(topn)\n",
        "\n",
        "        if verbose:\n",
        "            if self.items_df is None:\n",
        "                raise Exception('\"items_df\" is required in verbose mode')\n",
        "\n",
        "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
        "                                                          left_on = 'contentId', \n",
        "                                                          right_on = 'contentId')[['recStrength', 'contentId', 'title', 'url', 'lang']]\n",
        "\n",
        "\n",
        "        return recommendations_df\n",
        "    \n",
        "content_based_recommender_model = ContentBasedRecommender(articles_df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeMjkLMO42Eu",
        "colab_type": "text"
      },
      "source": [
        "With personalized recommendations of content-based filtering model, we have a Recall@5 to about 0.162, which means that about 16% of interacted items in test set were ranked by this model among the top-5 items (from lists with 100 random items). And Recall@10 was 0.261 (52%). The lower performance of the Content-Based model compared to the Popularity model may indicate that users are not that fixed in content very similar to their previous reads."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTzMWiTx425G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1ead9f1e-7bc9-418b-e1db-7dd43b06e4a2"
      },
      "source": [
        "print('Evaluating Content-Based Filtering model...')\n",
        "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model)\n",
        "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
        "cb_detailed_results_df.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating Content-Based Filtering model...\n",
            "1139 users processed\n",
            "\n",
            "Global metrics:\n",
            "{'modelName': 'Content-Based', 'recall@5': 0.16287394528253643, 'recall@10': 0.2614420864229097}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hits@5_count</th>\n",
              "      <th>hits@10_count</th>\n",
              "      <th>interacted_count</th>\n",
              "      <th>recall@5</th>\n",
              "      <th>recall@10</th>\n",
              "      <th>_person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>15</td>\n",
              "      <td>24</td>\n",
              "      <td>192</td>\n",
              "      <td>0.078125</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>3609194402293569455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>29</td>\n",
              "      <td>134</td>\n",
              "      <td>0.134328</td>\n",
              "      <td>0.216418</td>\n",
              "      <td>-2626634673110551643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>20</td>\n",
              "      <td>33</td>\n",
              "      <td>130</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.253846</td>\n",
              "      <td>-1032019229384696495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>32</td>\n",
              "      <td>47</td>\n",
              "      <td>117</td>\n",
              "      <td>0.273504</td>\n",
              "      <td>0.401709</td>\n",
              "      <td>-1443636648652872475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>88</td>\n",
              "      <td>0.068182</td>\n",
              "      <td>0.170455</td>\n",
              "      <td>-2979881261169775358</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    hits@5_count  hits@10_count  ...  recall@10           _person_id\n",
              "76            15             24  ...   0.125000  3609194402293569455\n",
              "17            18             29  ...   0.216418 -2626634673110551643\n",
              "16            20             33  ...   0.253846 -1032019229384696495\n",
              "10            32             47  ...   0.401709 -1443636648652872475\n",
              "82             6             15  ...   0.170455 -2979881261169775358\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNNCGC7q5Omi",
        "colab_type": "text"
      },
      "source": [
        "# Collaborative Filtering model\n",
        "\n",
        "Collaborative Filtering (CF) has two main implementation strategies:\n",
        "\n",
        "* **Memory-based**: This approach uses the memory of previous users interactions to compute users similarities based on items they've interacted (user-based approach) or compute items similarities based on the users that have interacted with them (item-based approach).\n",
        "A typical example of this approach is User Neighbourhood-based CF, in which the top-N similar users (usually computed using Pearson correlation) for a user are selected and used to recommend items those similar users liked, but the current user have not interacted yet. This approach is very simple to implement, but usually do not scale well for many users. A nice Python implementation of this approach in available in Crab.\n",
        "\n",
        "* **Model-based**: This approach, models are developed using different machine learning algorithms to recommend items to users. There are many model-based CF algorithms, like neural networks, bayesian networks, clustering models, and latent factor models such as Singular Value Decomposition (SVD) and, probabilistic latent semantic analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqvdwNCZ5ouS",
        "colab_type": "text"
      },
      "source": [
        "## Matrix Factorization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QlyiXwy5cFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "40e4279a-1f10-46fa-8e39-b332f2b6d5ba"
      },
      "source": [
        "#Creating a sparse pivot table with users in rows and items in columns\n",
        "users_items_pivot_matrix_df = interactions_train_df.pivot(index='personId', \n",
        "                                                          columns='contentId', \n",
        "                                                          values='eventWeight').fillna(0)\n",
        "\n",
        "users_items_pivot_matrix_df.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>contentId</th>\n",
              "      <th>-9222795471790223670</th>\n",
              "      <th>-9216926795620865886</th>\n",
              "      <th>-9194572880052200111</th>\n",
              "      <th>-9192549002213406534</th>\n",
              "      <th>-9190737901804729417</th>\n",
              "      <th>-9189659052158407108</th>\n",
              "      <th>-9176143510534135851</th>\n",
              "      <th>-9172673334835262304</th>\n",
              "      <th>-9171475473795142532</th>\n",
              "      <th>-9166778629773133902</th>\n",
              "      <th>-9161596996229760398</th>\n",
              "      <th>-9160910454530522563</th>\n",
              "      <th>-9157338616628196758</th>\n",
              "      <th>-9153494109165200346</th>\n",
              "      <th>-9147114693160126293</th>\n",
              "      <th>-9137036168156595470</th>\n",
              "      <th>-9128741757954228992</th>\n",
              "      <th>-9128652074338368262</th>\n",
              "      <th>-9107331682787867601</th>\n",
              "      <th>-9105040345021932755</th>\n",
              "      <th>-9103776596534246502</th>\n",
              "      <th>-9102431381393428051</th>\n",
              "      <th>-9100490342054218852</th>\n",
              "      <th>-9099155556042679205</th>\n",
              "      <th>-9095002324981651252</th>\n",
              "      <th>-9092333155845304874</th>\n",
              "      <th>-9090514312860140897</th>\n",
              "      <th>-9089854794058353436</th>\n",
              "      <th>-9086955082453789880</th>\n",
              "      <th>-9083294960368598209</th>\n",
              "      <th>-9081753261356157170</th>\n",
              "      <th>-9080873096647717414</th>\n",
              "      <th>-9076501258717815738</th>\n",
              "      <th>-9073210245497295284</th>\n",
              "      <th>-9071883412530082330</th>\n",
              "      <th>-9064100704535292718</th>\n",
              "      <th>-9056114023474725450</th>\n",
              "      <th>-9055044275358686874</th>\n",
              "      <th>-9050450867630628092</th>\n",
              "      <th>-9045753673721269477</th>\n",
              "      <th>...</th>\n",
              "      <th>8962537427807366481</th>\n",
              "      <th>8963770574956550187</th>\n",
              "      <th>8963938873430212934</th>\n",
              "      <th>8968837261991914049</th>\n",
              "      <th>8969476626572775042</th>\n",
              "      <th>8974280745225397183</th>\n",
              "      <th>8982094176562780806</th>\n",
              "      <th>8993230615635349817</th>\n",
              "      <th>9004099881383415529</th>\n",
              "      <th>9026402401132606773</th>\n",
              "      <th>9028580484484026894</th>\n",
              "      <th>9032993320407723266</th>\n",
              "      <th>9033884391004475493</th>\n",
              "      <th>9038543365726770177</th>\n",
              "      <th>9042192299854648021</th>\n",
              "      <th>9045808098977760576</th>\n",
              "      <th>9054050762437897017</th>\n",
              "      <th>9056727675613132316</th>\n",
              "      <th>9060231864899459154</th>\n",
              "      <th>9079880752026843473</th>\n",
              "      <th>9091641298512813712</th>\n",
              "      <th>9112765177685685246</th>\n",
              "      <th>9121100366909552616</th>\n",
              "      <th>9122627895188486603</th>\n",
              "      <th>9124439338148818380</th>\n",
              "      <th>9128267824356972069</th>\n",
              "      <th>9136323715291453594</th>\n",
              "      <th>9151634133568930081</th>\n",
              "      <th>9168028029170358424</th>\n",
              "      <th>9175693555063886126</th>\n",
              "      <th>9191014301634017491</th>\n",
              "      <th>9207286802575546269</th>\n",
              "      <th>9208127165664287660</th>\n",
              "      <th>9209629151177723638</th>\n",
              "      <th>9209886322932807692</th>\n",
              "      <th>9213260650272029784</th>\n",
              "      <th>9215261273565326920</th>\n",
              "      <th>9217155070834564627</th>\n",
              "      <th>9220445660318725468</th>\n",
              "      <th>9222265156747237864</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>personId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-9223121837663643404</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9212075797126931087</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9207251133131336884</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9199575329909162940</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9196668942822132778</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.321928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã 2926 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "contentId             -9222795471790223670  ...   9222265156747237864\n",
              "personId                                    ...                      \n",
              "-9223121837663643404                   0.0  ...                   0.0\n",
              "-9212075797126931087                   0.0  ...                   0.0\n",
              "-9207251133131336884                   0.0  ...                   0.0\n",
              "-9199575329909162940                   0.0  ...                   0.0\n",
              "-9196668942822132778                   0.0  ...                   0.0\n",
              "\n",
              "[5 rows x 2926 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u_3sZ9R5866",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "53b6e18f-376b-407f-8a27-a78aa361b3cf"
      },
      "source": [
        "users_items_pivot_matrix = users_items_pivot_matrix_df.values\n",
        "users_items_pivot_matrix[:10]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 2., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6CTZ2Ko677b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "70e09d5f-7132-47ba-d1b4-53638e7044a4"
      },
      "source": [
        "users_ids = list(users_items_pivot_matrix_df.index)\n",
        "users_ids[:10]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-9223121837663643404,\n",
              " -9212075797126931087,\n",
              " -9207251133131336884,\n",
              " -9199575329909162940,\n",
              " -9196668942822132778,\n",
              " -9188188261933657343,\n",
              " -9172914609055320039,\n",
              " -9156344805277471150,\n",
              " -9120685872592674274,\n",
              " -9109785559521267180]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0chpYkeT7ADQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1f7f764d-5a2d-4cbc-d146-9335c39ab1f0"
      },
      "source": [
        "users_items_pivot_sparse_matrix = csr_matrix(users_items_pivot_matrix)\n",
        "users_items_pivot_sparse_matrix"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1140x2926 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 31284 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbUWfar17EFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The number of factors to factor the user-item matrix.\n",
        "NUMBER_OF_FACTORS_MF = 15\n",
        "#Performs matrix factorization of the original user item matrix\n",
        "#U, sigma, Vt = svds(users_items_pivot_matrix, k = NUMBER_OF_FACTORS_MF)\n",
        "U, sigma, Vt = svds(users_items_pivot_sparse_matrix, k = NUMBER_OF_FACTORS_MF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSCy6djz7HPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52fe34e4-54db-4762-dea5-dc47713829c2"
      },
      "source": [
        "U.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1140, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwxIA_857IXq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "864e7527-0b07-493e-cd8f-404440c973c1"
      },
      "source": [
        "Vt.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 2926)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8h8aPpi7MX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98cc6c35-6eb4-45cc-ef26-a109dcc3a63e"
      },
      "source": [
        "sigma = np.diag(sigma)\n",
        "sigma.shape"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw8ByrrR7PYF",
        "colab_type": "text"
      },
      "source": [
        "After the factorization, we try to to reconstruct the original matrix by multiplying its factors. The resulting matrix is not sparse any more. It was generated predictions for items the user have not yet interaction, which we will exploit for recommendations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbIejrkq7Ol7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "5927d69a-64af-41d2-8efe-95bef50455ac"
      },
      "source": [
        "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n",
        "all_user_predicted_ratings"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01039915,  0.00081872, -0.01725263, ...,  0.00140708,\n",
              "         0.0110647 ,  0.00226063],\n",
              "       [-0.00019285, -0.00031318, -0.00264624, ...,  0.00251658,\n",
              "         0.00017609, -0.00189488],\n",
              "       [-0.01254721,  0.0065947 , -0.00590676, ...,  0.00698975,\n",
              "        -0.01015696,  0.01154572],\n",
              "       ...,\n",
              "       [-0.02995379,  0.00805715, -0.01846307, ..., -0.01083078,\n",
              "        -0.00118591,  0.0096798 ],\n",
              "       [-0.01845505,  0.00467019,  0.01219602, ...,  0.00409507,\n",
              "         0.00019482, -0.00752562],\n",
              "       [-0.01506374,  0.00327732,  0.13391269, ..., -0.01191815,\n",
              "         0.06422074,  0.01303244]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wids--Un7UUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_user_predicted_ratings_norm = (all_user_predicted_ratings - all_user_predicted_ratings.min()) / (all_user_predicted_ratings.max() - all_user_predicted_ratings.min())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdQbURld7dWx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "f93c0862-60ec-4030-c373-dcbdc47300ec"
      },
      "source": [
        "#Converting the reconstructed matrix back to a Pandas dataframe\n",
        "cf_preds_df = pd.DataFrame(all_user_predicted_ratings_norm, columns = users_items_pivot_matrix_df.columns, index=users_ids).transpose()\n",
        "cf_preds_df.head(10)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-9223121837663643404</th>\n",
              "      <th>-9212075797126931087</th>\n",
              "      <th>-9207251133131336884</th>\n",
              "      <th>-9199575329909162940</th>\n",
              "      <th>-9196668942822132778</th>\n",
              "      <th>-9188188261933657343</th>\n",
              "      <th>-9172914609055320039</th>\n",
              "      <th>-9156344805277471150</th>\n",
              "      <th>-9120685872592674274</th>\n",
              "      <th>-9109785559521267180</th>\n",
              "      <th>-9063420486253202900</th>\n",
              "      <th>-9060214117327732109</th>\n",
              "      <th>-9047547311469006438</th>\n",
              "      <th>-9016528795238256703</th>\n",
              "      <th>-9009798162809551896</th>\n",
              "      <th>-9001583565812478106</th>\n",
              "      <th>-8994220765455693336</th>\n",
              "      <th>-8909668725653743114</th>\n",
              "      <th>-8891033171626175843</th>\n",
              "      <th>-8860671864164757449</th>\n",
              "      <th>-8854674432071487111</th>\n",
              "      <th>-8853658195208337106</th>\n",
              "      <th>-8845298781299428018</th>\n",
              "      <th>-8830250090736356260</th>\n",
              "      <th>-8823950498314351783</th>\n",
              "      <th>-8802075878443651241</th>\n",
              "      <th>-8784674845716296727</th>\n",
              "      <th>-8781635134606732409</th>\n",
              "      <th>-8781306637602263252</th>\n",
              "      <th>-8763398617720485024</th>\n",
              "      <th>-8738496712327699923</th>\n",
              "      <th>-8719462623048086192</th>\n",
              "      <th>-8704807962619440953</th>\n",
              "      <th>-8699750646678621887</th>\n",
              "      <th>-8694104221113176052</th>\n",
              "      <th>-8686631410634491662</th>\n",
              "      <th>-8674958742744576254</th>\n",
              "      <th>-8672331451814079632</th>\n",
              "      <th>-8670749047273764903</th>\n",
              "      <th>-8652741825481604192</th>\n",
              "      <th>...</th>\n",
              "      <th>8791271631167250981</th>\n",
              "      <th>8801420707973230165</th>\n",
              "      <th>8801970869404590779</th>\n",
              "      <th>8813266398846460512</th>\n",
              "      <th>8841741572929644986</th>\n",
              "      <th>8847054836611412804</th>\n",
              "      <th>8855523843512271162</th>\n",
              "      <th>8862260182894039021</th>\n",
              "      <th>8872819156169667456</th>\n",
              "      <th>8874741321583329336</th>\n",
              "      <th>8879844298911979276</th>\n",
              "      <th>8892482595912468268</th>\n",
              "      <th>8907499588729810535</th>\n",
              "      <th>8913362709216003291</th>\n",
              "      <th>8920667914865172372</th>\n",
              "      <th>8940614478925413056</th>\n",
              "      <th>8941502917401491878</th>\n",
              "      <th>8961723342122872302</th>\n",
              "      <th>8965285988346645117</th>\n",
              "      <th>8968131284214320024</th>\n",
              "      <th>8982783231149017560</th>\n",
              "      <th>8992729171160464416</th>\n",
              "      <th>9013651444868609421</th>\n",
              "      <th>9033898219489253274</th>\n",
              "      <th>9037410398700100618</th>\n",
              "      <th>9038446466275805109</th>\n",
              "      <th>9050204922960952289</th>\n",
              "      <th>9090527742744334314</th>\n",
              "      <th>9091970136990402395</th>\n",
              "      <th>9102085903669288476</th>\n",
              "      <th>9105269044962898535</th>\n",
              "      <th>9109075639526981934</th>\n",
              "      <th>9135582630122950040</th>\n",
              "      <th>9137372837662939523</th>\n",
              "      <th>9148269800512008413</th>\n",
              "      <th>9165571805999894845</th>\n",
              "      <th>9187866633451383747</th>\n",
              "      <th>9191849144618614467</th>\n",
              "      <th>9199170757466086545</th>\n",
              "      <th>9210530975708218054</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contentId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-9222795471790223670</th>\n",
              "      <td>0.139129</td>\n",
              "      <td>0.137930</td>\n",
              "      <td>0.136531</td>\n",
              "      <td>0.143948</td>\n",
              "      <td>0.136815</td>\n",
              "      <td>0.137339</td>\n",
              "      <td>0.137508</td>\n",
              "      <td>0.143534</td>\n",
              "      <td>0.136428</td>\n",
              "      <td>0.135681</td>\n",
              "      <td>0.136873</td>\n",
              "      <td>0.138129</td>\n",
              "      <td>0.136588</td>\n",
              "      <td>0.130577</td>\n",
              "      <td>0.150717</td>\n",
              "      <td>0.142606</td>\n",
              "      <td>0.136765</td>\n",
              "      <td>0.137352</td>\n",
              "      <td>0.134002</td>\n",
              "      <td>0.124023</td>\n",
              "      <td>0.136944</td>\n",
              "      <td>0.133141</td>\n",
              "      <td>0.185105</td>\n",
              "      <td>0.134144</td>\n",
              "      <td>0.137539</td>\n",
              "      <td>0.137903</td>\n",
              "      <td>0.137115</td>\n",
              "      <td>0.137101</td>\n",
              "      <td>0.138658</td>\n",
              "      <td>0.144550</td>\n",
              "      <td>0.134712</td>\n",
              "      <td>0.142815</td>\n",
              "      <td>0.137962</td>\n",
              "      <td>0.137030</td>\n",
              "      <td>0.153129</td>\n",
              "      <td>0.137575</td>\n",
              "      <td>0.141602</td>\n",
              "      <td>0.134200</td>\n",
              "      <td>0.133515</td>\n",
              "      <td>0.138167</td>\n",
              "      <td>...</td>\n",
              "      <td>0.137972</td>\n",
              "      <td>0.140265</td>\n",
              "      <td>0.135848</td>\n",
              "      <td>0.140562</td>\n",
              "      <td>0.135223</td>\n",
              "      <td>0.137119</td>\n",
              "      <td>0.139497</td>\n",
              "      <td>0.135881</td>\n",
              "      <td>0.136262</td>\n",
              "      <td>0.136875</td>\n",
              "      <td>0.135751</td>\n",
              "      <td>0.137961</td>\n",
              "      <td>0.137583</td>\n",
              "      <td>0.137657</td>\n",
              "      <td>0.138469</td>\n",
              "      <td>0.136019</td>\n",
              "      <td>0.138092</td>\n",
              "      <td>0.137739</td>\n",
              "      <td>0.137670</td>\n",
              "      <td>0.195783</td>\n",
              "      <td>0.137108</td>\n",
              "      <td>0.135888</td>\n",
              "      <td>0.137397</td>\n",
              "      <td>0.136848</td>\n",
              "      <td>0.138275</td>\n",
              "      <td>0.138327</td>\n",
              "      <td>0.137143</td>\n",
              "      <td>0.137248</td>\n",
              "      <td>0.139015</td>\n",
              "      <td>0.141458</td>\n",
              "      <td>0.137351</td>\n",
              "      <td>0.127822</td>\n",
              "      <td>0.137946</td>\n",
              "      <td>0.139653</td>\n",
              "      <td>0.140324</td>\n",
              "      <td>0.136888</td>\n",
              "      <td>0.135787</td>\n",
              "      <td>0.134560</td>\n",
              "      <td>0.135862</td>\n",
              "      <td>0.136246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9216926795620865886</th>\n",
              "      <td>0.138044</td>\n",
              "      <td>0.137916</td>\n",
              "      <td>0.138698</td>\n",
              "      <td>0.137878</td>\n",
              "      <td>0.137969</td>\n",
              "      <td>0.137990</td>\n",
              "      <td>0.137974</td>\n",
              "      <td>0.138049</td>\n",
              "      <td>0.138217</td>\n",
              "      <td>0.138151</td>\n",
              "      <td>0.138030</td>\n",
              "      <td>0.137906</td>\n",
              "      <td>0.137802</td>\n",
              "      <td>0.139819</td>\n",
              "      <td>0.139060</td>\n",
              "      <td>0.138581</td>\n",
              "      <td>0.138495</td>\n",
              "      <td>0.138178</td>\n",
              "      <td>0.138921</td>\n",
              "      <td>0.142132</td>\n",
              "      <td>0.138560</td>\n",
              "      <td>0.140137</td>\n",
              "      <td>0.136909</td>\n",
              "      <td>0.137947</td>\n",
              "      <td>0.138055</td>\n",
              "      <td>0.138029</td>\n",
              "      <td>0.138159</td>\n",
              "      <td>0.137973</td>\n",
              "      <td>0.138319</td>\n",
              "      <td>0.139002</td>\n",
              "      <td>0.138095</td>\n",
              "      <td>0.138327</td>\n",
              "      <td>0.137942</td>\n",
              "      <td>0.138777</td>\n",
              "      <td>0.138120</td>\n",
              "      <td>0.137983</td>\n",
              "      <td>0.138999</td>\n",
              "      <td>0.138718</td>\n",
              "      <td>0.139083</td>\n",
              "      <td>0.137882</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138007</td>\n",
              "      <td>0.138102</td>\n",
              "      <td>0.137982</td>\n",
              "      <td>0.138226</td>\n",
              "      <td>0.138274</td>\n",
              "      <td>0.137751</td>\n",
              "      <td>0.138323</td>\n",
              "      <td>0.138471</td>\n",
              "      <td>0.138529</td>\n",
              "      <td>0.137938</td>\n",
              "      <td>0.138427</td>\n",
              "      <td>0.138162</td>\n",
              "      <td>0.138104</td>\n",
              "      <td>0.137846</td>\n",
              "      <td>0.139777</td>\n",
              "      <td>0.138316</td>\n",
              "      <td>0.138128</td>\n",
              "      <td>0.138197</td>\n",
              "      <td>0.138029</td>\n",
              "      <td>0.140776</td>\n",
              "      <td>0.137905</td>\n",
              "      <td>0.138269</td>\n",
              "      <td>0.137898</td>\n",
              "      <td>0.138227</td>\n",
              "      <td>0.137861</td>\n",
              "      <td>0.138231</td>\n",
              "      <td>0.138039</td>\n",
              "      <td>0.137939</td>\n",
              "      <td>0.138106</td>\n",
              "      <td>0.137890</td>\n",
              "      <td>0.137962</td>\n",
              "      <td>0.139527</td>\n",
              "      <td>0.138009</td>\n",
              "      <td>0.138117</td>\n",
              "      <td>0.139634</td>\n",
              "      <td>0.138058</td>\n",
              "      <td>0.138222</td>\n",
              "      <td>0.138864</td>\n",
              "      <td>0.138480</td>\n",
              "      <td>0.138323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9194572880052200111</th>\n",
              "      <td>0.135998</td>\n",
              "      <td>0.137652</td>\n",
              "      <td>0.137283</td>\n",
              "      <td>0.137536</td>\n",
              "      <td>0.140363</td>\n",
              "      <td>0.137807</td>\n",
              "      <td>0.141246</td>\n",
              "      <td>0.136284</td>\n",
              "      <td>0.135301</td>\n",
              "      <td>0.138512</td>\n",
              "      <td>0.140841</td>\n",
              "      <td>0.138711</td>\n",
              "      <td>0.139789</td>\n",
              "      <td>0.128246</td>\n",
              "      <td>0.144622</td>\n",
              "      <td>0.141345</td>\n",
              "      <td>0.137643</td>\n",
              "      <td>0.139323</td>\n",
              "      <td>0.137696</td>\n",
              "      <td>0.139703</td>\n",
              "      <td>0.137689</td>\n",
              "      <td>0.156370</td>\n",
              "      <td>0.125468</td>\n",
              "      <td>0.142828</td>\n",
              "      <td>0.138392</td>\n",
              "      <td>0.138221</td>\n",
              "      <td>0.140230</td>\n",
              "      <td>0.137840</td>\n",
              "      <td>0.148801</td>\n",
              "      <td>0.146963</td>\n",
              "      <td>0.136267</td>\n",
              "      <td>0.141754</td>\n",
              "      <td>0.138444</td>\n",
              "      <td>0.140615</td>\n",
              "      <td>0.131440</td>\n",
              "      <td>0.138559</td>\n",
              "      <td>0.147311</td>\n",
              "      <td>0.139779</td>\n",
              "      <td>0.147000</td>\n",
              "      <td>0.140466</td>\n",
              "      <td>...</td>\n",
              "      <td>0.137886</td>\n",
              "      <td>0.139455</td>\n",
              "      <td>0.137283</td>\n",
              "      <td>0.136793</td>\n",
              "      <td>0.139520</td>\n",
              "      <td>0.139865</td>\n",
              "      <td>0.146728</td>\n",
              "      <td>0.137552</td>\n",
              "      <td>0.142963</td>\n",
              "      <td>0.139664</td>\n",
              "      <td>0.144436</td>\n",
              "      <td>0.141681</td>\n",
              "      <td>0.139307</td>\n",
              "      <td>0.139046</td>\n",
              "      <td>0.138571</td>\n",
              "      <td>0.135371</td>\n",
              "      <td>0.139288</td>\n",
              "      <td>0.138132</td>\n",
              "      <td>0.137715</td>\n",
              "      <td>0.149994</td>\n",
              "      <td>0.138013</td>\n",
              "      <td>0.139390</td>\n",
              "      <td>0.137086</td>\n",
              "      <td>0.137759</td>\n",
              "      <td>0.137799</td>\n",
              "      <td>0.140283</td>\n",
              "      <td>0.138518</td>\n",
              "      <td>0.138112</td>\n",
              "      <td>0.139763</td>\n",
              "      <td>0.136812</td>\n",
              "      <td>0.139257</td>\n",
              "      <td>0.143161</td>\n",
              "      <td>0.139139</td>\n",
              "      <td>0.140077</td>\n",
              "      <td>0.154976</td>\n",
              "      <td>0.140109</td>\n",
              "      <td>0.140654</td>\n",
              "      <td>0.135861</td>\n",
              "      <td>0.139332</td>\n",
              "      <td>0.153114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9192549002213406534</th>\n",
              "      <td>0.141924</td>\n",
              "      <td>0.137996</td>\n",
              "      <td>0.134663</td>\n",
              "      <td>0.137080</td>\n",
              "      <td>0.139946</td>\n",
              "      <td>0.138574</td>\n",
              "      <td>0.139473</td>\n",
              "      <td>0.144469</td>\n",
              "      <td>0.143333</td>\n",
              "      <td>0.138428</td>\n",
              "      <td>0.141432</td>\n",
              "      <td>0.137050</td>\n",
              "      <td>0.137440</td>\n",
              "      <td>0.253586</td>\n",
              "      <td>0.235253</td>\n",
              "      <td>0.152683</td>\n",
              "      <td>0.139437</td>\n",
              "      <td>0.138290</td>\n",
              "      <td>0.133682</td>\n",
              "      <td>0.162980</td>\n",
              "      <td>0.135424</td>\n",
              "      <td>0.163190</td>\n",
              "      <td>0.180049</td>\n",
              "      <td>0.147092</td>\n",
              "      <td>0.139735</td>\n",
              "      <td>0.137446</td>\n",
              "      <td>0.139441</td>\n",
              "      <td>0.139040</td>\n",
              "      <td>0.154785</td>\n",
              "      <td>0.149483</td>\n",
              "      <td>0.139090</td>\n",
              "      <td>0.134246</td>\n",
              "      <td>0.139747</td>\n",
              "      <td>0.135225</td>\n",
              "      <td>0.138831</td>\n",
              "      <td>0.140566</td>\n",
              "      <td>0.148091</td>\n",
              "      <td>0.134264</td>\n",
              "      <td>0.139635</td>\n",
              "      <td>0.144029</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138287</td>\n",
              "      <td>0.140515</td>\n",
              "      <td>0.142015</td>\n",
              "      <td>0.138465</td>\n",
              "      <td>0.142294</td>\n",
              "      <td>0.139936</td>\n",
              "      <td>0.151212</td>\n",
              "      <td>0.141403</td>\n",
              "      <td>0.144641</td>\n",
              "      <td>0.141462</td>\n",
              "      <td>0.152350</td>\n",
              "      <td>0.136734</td>\n",
              "      <td>0.139035</td>\n",
              "      <td>0.142453</td>\n",
              "      <td>0.133068</td>\n",
              "      <td>0.134365</td>\n",
              "      <td>0.140076</td>\n",
              "      <td>0.137809</td>\n",
              "      <td>0.138090</td>\n",
              "      <td>0.119932</td>\n",
              "      <td>0.138428</td>\n",
              "      <td>0.139932</td>\n",
              "      <td>0.139678</td>\n",
              "      <td>0.137343</td>\n",
              "      <td>0.136723</td>\n",
              "      <td>0.138767</td>\n",
              "      <td>0.138920</td>\n",
              "      <td>0.133864</td>\n",
              "      <td>0.135980</td>\n",
              "      <td>0.137682</td>\n",
              "      <td>0.140233</td>\n",
              "      <td>0.167426</td>\n",
              "      <td>0.138849</td>\n",
              "      <td>0.137037</td>\n",
              "      <td>0.141820</td>\n",
              "      <td>0.139260</td>\n",
              "      <td>0.139513</td>\n",
              "      <td>0.136804</td>\n",
              "      <td>0.140862</td>\n",
              "      <td>0.148793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9190737901804729417</th>\n",
              "      <td>0.140209</td>\n",
              "      <td>0.137408</td>\n",
              "      <td>0.138708</td>\n",
              "      <td>0.138672</td>\n",
              "      <td>0.137725</td>\n",
              "      <td>0.138218</td>\n",
              "      <td>0.138390</td>\n",
              "      <td>0.138418</td>\n",
              "      <td>0.134883</td>\n",
              "      <td>0.140193</td>\n",
              "      <td>0.137848</td>\n",
              "      <td>0.137132</td>\n",
              "      <td>0.137786</td>\n",
              "      <td>0.148162</td>\n",
              "      <td>0.144360</td>\n",
              "      <td>0.140212</td>\n",
              "      <td>0.139569</td>\n",
              "      <td>0.137746</td>\n",
              "      <td>0.139078</td>\n",
              "      <td>0.146346</td>\n",
              "      <td>0.138870</td>\n",
              "      <td>0.134916</td>\n",
              "      <td>0.147783</td>\n",
              "      <td>0.138158</td>\n",
              "      <td>0.138010</td>\n",
              "      <td>0.137924</td>\n",
              "      <td>0.137945</td>\n",
              "      <td>0.138067</td>\n",
              "      <td>0.137276</td>\n",
              "      <td>0.137474</td>\n",
              "      <td>0.138648</td>\n",
              "      <td>0.139118</td>\n",
              "      <td>0.137669</td>\n",
              "      <td>0.137727</td>\n",
              "      <td>0.141712</td>\n",
              "      <td>0.137811</td>\n",
              "      <td>0.138825</td>\n",
              "      <td>0.138713</td>\n",
              "      <td>0.137949</td>\n",
              "      <td>0.135816</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138180</td>\n",
              "      <td>0.138211</td>\n",
              "      <td>0.137050</td>\n",
              "      <td>0.139103</td>\n",
              "      <td>0.140882</td>\n",
              "      <td>0.138625</td>\n",
              "      <td>0.138923</td>\n",
              "      <td>0.138504</td>\n",
              "      <td>0.137251</td>\n",
              "      <td>0.137114</td>\n",
              "      <td>0.138708</td>\n",
              "      <td>0.138862</td>\n",
              "      <td>0.137848</td>\n",
              "      <td>0.137826</td>\n",
              "      <td>0.140804</td>\n",
              "      <td>0.140277</td>\n",
              "      <td>0.137831</td>\n",
              "      <td>0.138420</td>\n",
              "      <td>0.137559</td>\n",
              "      <td>0.146108</td>\n",
              "      <td>0.138105</td>\n",
              "      <td>0.137986</td>\n",
              "      <td>0.136776</td>\n",
              "      <td>0.138272</td>\n",
              "      <td>0.137808</td>\n",
              "      <td>0.137968</td>\n",
              "      <td>0.138111</td>\n",
              "      <td>0.137828</td>\n",
              "      <td>0.137993</td>\n",
              "      <td>0.138804</td>\n",
              "      <td>0.138373</td>\n",
              "      <td>0.138459</td>\n",
              "      <td>0.138169</td>\n",
              "      <td>0.137990</td>\n",
              "      <td>0.134041</td>\n",
              "      <td>0.137820</td>\n",
              "      <td>0.138100</td>\n",
              "      <td>0.138286</td>\n",
              "      <td>0.138630</td>\n",
              "      <td>0.136178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9189659052158407108</th>\n",
              "      <td>0.138932</td>\n",
              "      <td>0.138699</td>\n",
              "      <td>0.138117</td>\n",
              "      <td>0.137621</td>\n",
              "      <td>0.138920</td>\n",
              "      <td>0.137766</td>\n",
              "      <td>0.138568</td>\n",
              "      <td>0.138200</td>\n",
              "      <td>0.140572</td>\n",
              "      <td>0.140365</td>\n",
              "      <td>0.138838</td>\n",
              "      <td>0.138162</td>\n",
              "      <td>0.139325</td>\n",
              "      <td>0.213018</td>\n",
              "      <td>0.164275</td>\n",
              "      <td>0.141652</td>\n",
              "      <td>0.139104</td>\n",
              "      <td>0.138069</td>\n",
              "      <td>0.136997</td>\n",
              "      <td>0.142442</td>\n",
              "      <td>0.138298</td>\n",
              "      <td>0.157560</td>\n",
              "      <td>0.140603</td>\n",
              "      <td>0.143308</td>\n",
              "      <td>0.139266</td>\n",
              "      <td>0.141019</td>\n",
              "      <td>0.141666</td>\n",
              "      <td>0.139284</td>\n",
              "      <td>0.145634</td>\n",
              "      <td>0.145712</td>\n",
              "      <td>0.138731</td>\n",
              "      <td>0.139108</td>\n",
              "      <td>0.138941</td>\n",
              "      <td>0.138897</td>\n",
              "      <td>0.138374</td>\n",
              "      <td>0.138844</td>\n",
              "      <td>0.147596</td>\n",
              "      <td>0.138761</td>\n",
              "      <td>0.141678</td>\n",
              "      <td>0.141520</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138005</td>\n",
              "      <td>0.139644</td>\n",
              "      <td>0.139885</td>\n",
              "      <td>0.137190</td>\n",
              "      <td>0.140919</td>\n",
              "      <td>0.139032</td>\n",
              "      <td>0.143909</td>\n",
              "      <td>0.139763</td>\n",
              "      <td>0.147707</td>\n",
              "      <td>0.139447</td>\n",
              "      <td>0.144665</td>\n",
              "      <td>0.138382</td>\n",
              "      <td>0.138796</td>\n",
              "      <td>0.139262</td>\n",
              "      <td>0.141341</td>\n",
              "      <td>0.137985</td>\n",
              "      <td>0.139236</td>\n",
              "      <td>0.138246</td>\n",
              "      <td>0.138058</td>\n",
              "      <td>0.130773</td>\n",
              "      <td>0.137865</td>\n",
              "      <td>0.139564</td>\n",
              "      <td>0.142723</td>\n",
              "      <td>0.138340</td>\n",
              "      <td>0.138232</td>\n",
              "      <td>0.139038</td>\n",
              "      <td>0.138716</td>\n",
              "      <td>0.138014</td>\n",
              "      <td>0.138794</td>\n",
              "      <td>0.137751</td>\n",
              "      <td>0.140725</td>\n",
              "      <td>0.148152</td>\n",
              "      <td>0.137645</td>\n",
              "      <td>0.138165</td>\n",
              "      <td>0.149152</td>\n",
              "      <td>0.138912</td>\n",
              "      <td>0.139595</td>\n",
              "      <td>0.139807</td>\n",
              "      <td>0.140419</td>\n",
              "      <td>0.145698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9176143510534135851</th>\n",
              "      <td>0.143208</td>\n",
              "      <td>0.138673</td>\n",
              "      <td>0.139514</td>\n",
              "      <td>0.139114</td>\n",
              "      <td>0.137664</td>\n",
              "      <td>0.137447</td>\n",
              "      <td>0.139833</td>\n",
              "      <td>0.140564</td>\n",
              "      <td>0.144698</td>\n",
              "      <td>0.144440</td>\n",
              "      <td>0.137037</td>\n",
              "      <td>0.139572</td>\n",
              "      <td>0.139007</td>\n",
              "      <td>0.138290</td>\n",
              "      <td>0.145871</td>\n",
              "      <td>0.140543</td>\n",
              "      <td>0.140147</td>\n",
              "      <td>0.137642</td>\n",
              "      <td>0.142022</td>\n",
              "      <td>0.163576</td>\n",
              "      <td>0.139253</td>\n",
              "      <td>0.160965</td>\n",
              "      <td>0.153690</td>\n",
              "      <td>0.138399</td>\n",
              "      <td>0.139201</td>\n",
              "      <td>0.140534</td>\n",
              "      <td>0.140724</td>\n",
              "      <td>0.138407</td>\n",
              "      <td>0.135384</td>\n",
              "      <td>0.140066</td>\n",
              "      <td>0.138851</td>\n",
              "      <td>0.138763</td>\n",
              "      <td>0.138403</td>\n",
              "      <td>0.138128</td>\n",
              "      <td>0.150533</td>\n",
              "      <td>0.138263</td>\n",
              "      <td>0.141087</td>\n",
              "      <td>0.138972</td>\n",
              "      <td>0.137039</td>\n",
              "      <td>0.142258</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138115</td>\n",
              "      <td>0.139960</td>\n",
              "      <td>0.139978</td>\n",
              "      <td>0.140019</td>\n",
              "      <td>0.141414</td>\n",
              "      <td>0.137447</td>\n",
              "      <td>0.136664</td>\n",
              "      <td>0.139216</td>\n",
              "      <td>0.145822</td>\n",
              "      <td>0.140441</td>\n",
              "      <td>0.137722</td>\n",
              "      <td>0.139495</td>\n",
              "      <td>0.139414</td>\n",
              "      <td>0.138127</td>\n",
              "      <td>0.144116</td>\n",
              "      <td>0.140592</td>\n",
              "      <td>0.139934</td>\n",
              "      <td>0.139089</td>\n",
              "      <td>0.139481</td>\n",
              "      <td>0.136901</td>\n",
              "      <td>0.137552</td>\n",
              "      <td>0.137265</td>\n",
              "      <td>0.143057</td>\n",
              "      <td>0.138473</td>\n",
              "      <td>0.138530</td>\n",
              "      <td>0.138036</td>\n",
              "      <td>0.138650</td>\n",
              "      <td>0.138920</td>\n",
              "      <td>0.137099</td>\n",
              "      <td>0.138868</td>\n",
              "      <td>0.138367</td>\n",
              "      <td>0.146220</td>\n",
              "      <td>0.136204</td>\n",
              "      <td>0.138087</td>\n",
              "      <td>0.137317</td>\n",
              "      <td>0.137917</td>\n",
              "      <td>0.138546</td>\n",
              "      <td>0.142601</td>\n",
              "      <td>0.141431</td>\n",
              "      <td>0.142154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9172673334835262304</th>\n",
              "      <td>0.138527</td>\n",
              "      <td>0.138021</td>\n",
              "      <td>0.138274</td>\n",
              "      <td>0.137827</td>\n",
              "      <td>0.137997</td>\n",
              "      <td>0.138037</td>\n",
              "      <td>0.138104</td>\n",
              "      <td>0.138259</td>\n",
              "      <td>0.137633</td>\n",
              "      <td>0.138397</td>\n",
              "      <td>0.138124</td>\n",
              "      <td>0.137687</td>\n",
              "      <td>0.137719</td>\n",
              "      <td>0.147690</td>\n",
              "      <td>0.142882</td>\n",
              "      <td>0.139122</td>\n",
              "      <td>0.138471</td>\n",
              "      <td>0.137915</td>\n",
              "      <td>0.138650</td>\n",
              "      <td>0.143494</td>\n",
              "      <td>0.138325</td>\n",
              "      <td>0.138763</td>\n",
              "      <td>0.139561</td>\n",
              "      <td>0.138153</td>\n",
              "      <td>0.138052</td>\n",
              "      <td>0.137808</td>\n",
              "      <td>0.138060</td>\n",
              "      <td>0.138083</td>\n",
              "      <td>0.138665</td>\n",
              "      <td>0.138258</td>\n",
              "      <td>0.138266</td>\n",
              "      <td>0.137641</td>\n",
              "      <td>0.137953</td>\n",
              "      <td>0.137883</td>\n",
              "      <td>0.139041</td>\n",
              "      <td>0.137951</td>\n",
              "      <td>0.138003</td>\n",
              "      <td>0.138507</td>\n",
              "      <td>0.137875</td>\n",
              "      <td>0.137137</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138013</td>\n",
              "      <td>0.137970</td>\n",
              "      <td>0.137831</td>\n",
              "      <td>0.138373</td>\n",
              "      <td>0.139015</td>\n",
              "      <td>0.137767</td>\n",
              "      <td>0.139002</td>\n",
              "      <td>0.138571</td>\n",
              "      <td>0.137622</td>\n",
              "      <td>0.137229</td>\n",
              "      <td>0.138657</td>\n",
              "      <td>0.138131</td>\n",
              "      <td>0.138006</td>\n",
              "      <td>0.137721</td>\n",
              "      <td>0.138751</td>\n",
              "      <td>0.138310</td>\n",
              "      <td>0.138028</td>\n",
              "      <td>0.138110</td>\n",
              "      <td>0.138025</td>\n",
              "      <td>0.135660</td>\n",
              "      <td>0.137991</td>\n",
              "      <td>0.138163</td>\n",
              "      <td>0.137772</td>\n",
              "      <td>0.138156</td>\n",
              "      <td>0.137801</td>\n",
              "      <td>0.138019</td>\n",
              "      <td>0.138045</td>\n",
              "      <td>0.137532</td>\n",
              "      <td>0.137743</td>\n",
              "      <td>0.137996</td>\n",
              "      <td>0.138588</td>\n",
              "      <td>0.140146</td>\n",
              "      <td>0.138013</td>\n",
              "      <td>0.137839</td>\n",
              "      <td>0.137033</td>\n",
              "      <td>0.137969</td>\n",
              "      <td>0.138337</td>\n",
              "      <td>0.138361</td>\n",
              "      <td>0.138813</td>\n",
              "      <td>0.137538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9171475473795142532</th>\n",
              "      <td>0.140720</td>\n",
              "      <td>0.137865</td>\n",
              "      <td>0.138061</td>\n",
              "      <td>0.137633</td>\n",
              "      <td>0.138231</td>\n",
              "      <td>0.138089</td>\n",
              "      <td>0.139009</td>\n",
              "      <td>0.137552</td>\n",
              "      <td>0.137143</td>\n",
              "      <td>0.140581</td>\n",
              "      <td>0.137960</td>\n",
              "      <td>0.137638</td>\n",
              "      <td>0.138558</td>\n",
              "      <td>0.141247</td>\n",
              "      <td>0.133906</td>\n",
              "      <td>0.138897</td>\n",
              "      <td>0.138973</td>\n",
              "      <td>0.137978</td>\n",
              "      <td>0.139747</td>\n",
              "      <td>0.146615</td>\n",
              "      <td>0.137988</td>\n",
              "      <td>0.138377</td>\n",
              "      <td>0.137588</td>\n",
              "      <td>0.139037</td>\n",
              "      <td>0.138106</td>\n",
              "      <td>0.138201</td>\n",
              "      <td>0.138601</td>\n",
              "      <td>0.138206</td>\n",
              "      <td>0.138902</td>\n",
              "      <td>0.137628</td>\n",
              "      <td>0.138988</td>\n",
              "      <td>0.137200</td>\n",
              "      <td>0.137896</td>\n",
              "      <td>0.137950</td>\n",
              "      <td>0.141161</td>\n",
              "      <td>0.138193</td>\n",
              "      <td>0.138098</td>\n",
              "      <td>0.139383</td>\n",
              "      <td>0.139136</td>\n",
              "      <td>0.136194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138044</td>\n",
              "      <td>0.138177</td>\n",
              "      <td>0.137945</td>\n",
              "      <td>0.138293</td>\n",
              "      <td>0.142048</td>\n",
              "      <td>0.138000</td>\n",
              "      <td>0.138775</td>\n",
              "      <td>0.137968</td>\n",
              "      <td>0.138319</td>\n",
              "      <td>0.138089</td>\n",
              "      <td>0.138580</td>\n",
              "      <td>0.139681</td>\n",
              "      <td>0.138415</td>\n",
              "      <td>0.137954</td>\n",
              "      <td>0.139855</td>\n",
              "      <td>0.139614</td>\n",
              "      <td>0.137906</td>\n",
              "      <td>0.138358</td>\n",
              "      <td>0.137997</td>\n",
              "      <td>0.135661</td>\n",
              "      <td>0.138221</td>\n",
              "      <td>0.138732</td>\n",
              "      <td>0.137743</td>\n",
              "      <td>0.138101</td>\n",
              "      <td>0.138034</td>\n",
              "      <td>0.137962</td>\n",
              "      <td>0.138095</td>\n",
              "      <td>0.138483</td>\n",
              "      <td>0.137764</td>\n",
              "      <td>0.138149</td>\n",
              "      <td>0.139046</td>\n",
              "      <td>0.139895</td>\n",
              "      <td>0.138000</td>\n",
              "      <td>0.137958</td>\n",
              "      <td>0.136061</td>\n",
              "      <td>0.138183</td>\n",
              "      <td>0.138817</td>\n",
              "      <td>0.138060</td>\n",
              "      <td>0.139205</td>\n",
              "      <td>0.137198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9166778629773133902</th>\n",
              "      <td>0.138989</td>\n",
              "      <td>0.137725</td>\n",
              "      <td>0.136520</td>\n",
              "      <td>0.137723</td>\n",
              "      <td>0.138559</td>\n",
              "      <td>0.137951</td>\n",
              "      <td>0.138189</td>\n",
              "      <td>0.138496</td>\n",
              "      <td>0.139470</td>\n",
              "      <td>0.137546</td>\n",
              "      <td>0.138630</td>\n",
              "      <td>0.137676</td>\n",
              "      <td>0.138066</td>\n",
              "      <td>0.158558</td>\n",
              "      <td>0.153516</td>\n",
              "      <td>0.139702</td>\n",
              "      <td>0.137782</td>\n",
              "      <td>0.138073</td>\n",
              "      <td>0.136269</td>\n",
              "      <td>0.138271</td>\n",
              "      <td>0.136644</td>\n",
              "      <td>0.142122</td>\n",
              "      <td>0.140998</td>\n",
              "      <td>0.140776</td>\n",
              "      <td>0.138403</td>\n",
              "      <td>0.137915</td>\n",
              "      <td>0.138410</td>\n",
              "      <td>0.138160</td>\n",
              "      <td>0.141377</td>\n",
              "      <td>0.140371</td>\n",
              "      <td>0.138412</td>\n",
              "      <td>0.136175</td>\n",
              "      <td>0.138426</td>\n",
              "      <td>0.137240</td>\n",
              "      <td>0.137603</td>\n",
              "      <td>0.138815</td>\n",
              "      <td>0.140432</td>\n",
              "      <td>0.136503</td>\n",
              "      <td>0.138786</td>\n",
              "      <td>0.138652</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138021</td>\n",
              "      <td>0.138441</td>\n",
              "      <td>0.139079</td>\n",
              "      <td>0.137444</td>\n",
              "      <td>0.138811</td>\n",
              "      <td>0.138559</td>\n",
              "      <td>0.140123</td>\n",
              "      <td>0.137958</td>\n",
              "      <td>0.140152</td>\n",
              "      <td>0.138944</td>\n",
              "      <td>0.141430</td>\n",
              "      <td>0.137672</td>\n",
              "      <td>0.138352</td>\n",
              "      <td>0.138905</td>\n",
              "      <td>0.135974</td>\n",
              "      <td>0.136886</td>\n",
              "      <td>0.138352</td>\n",
              "      <td>0.137775</td>\n",
              "      <td>0.137755</td>\n",
              "      <td>0.130601</td>\n",
              "      <td>0.138090</td>\n",
              "      <td>0.138606</td>\n",
              "      <td>0.138019</td>\n",
              "      <td>0.137581</td>\n",
              "      <td>0.137746</td>\n",
              "      <td>0.137918</td>\n",
              "      <td>0.138104</td>\n",
              "      <td>0.137426</td>\n",
              "      <td>0.137415</td>\n",
              "      <td>0.137869</td>\n",
              "      <td>0.138233</td>\n",
              "      <td>0.144002</td>\n",
              "      <td>0.138050</td>\n",
              "      <td>0.137533</td>\n",
              "      <td>0.139036</td>\n",
              "      <td>0.138399</td>\n",
              "      <td>0.138330</td>\n",
              "      <td>0.137148</td>\n",
              "      <td>0.138027</td>\n",
              "      <td>0.140283</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows Ã 1140 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      -9223121837663643404  ...   9210530975708218054\n",
              "contentId                                   ...                      \n",
              "-9222795471790223670              0.139129  ...              0.136246\n",
              "-9216926795620865886              0.138044  ...              0.138323\n",
              "-9194572880052200111              0.135998  ...              0.153114\n",
              "-9192549002213406534              0.141924  ...              0.148793\n",
              "-9190737901804729417              0.140209  ...              0.136178\n",
              "-9189659052158407108              0.138932  ...              0.145698\n",
              "-9176143510534135851              0.143208  ...              0.142154\n",
              "-9172673334835262304              0.138527  ...              0.137538\n",
              "-9171475473795142532              0.140720  ...              0.137198\n",
              "-9166778629773133902              0.138989  ...              0.140283\n",
              "\n",
              "[10 rows x 1140 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWS7JmiL7gw1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0be2cd77-638d-41f0-d0b3-303aaaeb55fa"
      },
      "source": [
        "len(cf_preds_df.columns)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtX6IL007jIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CFRecommender:\n",
        "    \n",
        "    MODEL_NAME = 'Collaborative Filtering'\n",
        "    \n",
        "    def __init__(self, cf_predictions_df, items_df=None):\n",
        "        self.cf_predictions_df = cf_predictions_df\n",
        "        self.items_df = items_df\n",
        "        \n",
        "    def get_model_name(self):\n",
        "        return self.MODEL_NAME\n",
        "        \n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
        "        # Get and sort the user's predictions\n",
        "        sorted_user_predictions = self.cf_predictions_df[user_id].sort_values(ascending=False) \\\n",
        "                                    .reset_index().rename(columns={user_id: 'recStrength'})\n",
        "\n",
        "        # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
        "        recommendations_df = sorted_user_predictions[~sorted_user_predictions['contentId'].isin(items_to_ignore)] \\\n",
        "                               .sort_values('recStrength', ascending = False) \\\n",
        "                               .head(topn)\n",
        "\n",
        "        if verbose:\n",
        "            if self.items_df is None:\n",
        "                raise Exception('\"items_df\" is required in verbose mode')\n",
        "\n",
        "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
        "                                                          left_on = 'contentId', \n",
        "                                                          right_on = 'contentId')[['recStrength', 'contentId', 'title', 'url', 'lang']]\n",
        "\n",
        "\n",
        "        return recommendations_df\n",
        "    \n",
        "cf_recommender_model = CFRecommender(cf_preds_df, articles_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV9RuU7q7zoU",
        "colab_type": "text"
      },
      "source": [
        "Evaluating the Collaborative Filtering model (SVD matrix factorization), we observe that we got Recall@5 (33%) and Recall@10 (46%) values, much higher than Popularity model and Content-Based model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3eOkAHq72dF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "f94c50c0-dd1e-4b60-c214-30d63a6ad119"
      },
      "source": [
        "print('Evaluating Collaborative Filtering (SVD Matrix Factorization) model...')\n",
        "cf_global_metrics, cf_detailed_results_df = model_evaluator.evaluate_model(cf_recommender_model)\n",
        "print('\\nGlobal metrics:\\n%s' % cf_global_metrics)\n",
        "cf_detailed_results_df.head(10)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating Collaborative Filtering (SVD Matrix Factorization) model...\n",
            "1139 users processed\n",
            "\n",
            "Global metrics:\n",
            "{'modelName': 'Collaborative Filtering', 'recall@5': 0.33405778573254924, 'recall@10': 0.46816670928151366}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hits@5_count</th>\n",
              "      <th>hits@10_count</th>\n",
              "      <th>interacted_count</th>\n",
              "      <th>recall@5</th>\n",
              "      <th>recall@10</th>\n",
              "      <th>_person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>21</td>\n",
              "      <td>45</td>\n",
              "      <td>192</td>\n",
              "      <td>0.109375</td>\n",
              "      <td>0.234375</td>\n",
              "      <td>3609194402293569455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>30</td>\n",
              "      <td>56</td>\n",
              "      <td>134</td>\n",
              "      <td>0.223881</td>\n",
              "      <td>0.417910</td>\n",
              "      <td>-2626634673110551643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>34</td>\n",
              "      <td>130</td>\n",
              "      <td>0.123077</td>\n",
              "      <td>0.261538</td>\n",
              "      <td>-1032019229384696495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>38</td>\n",
              "      <td>51</td>\n",
              "      <td>117</td>\n",
              "      <td>0.324786</td>\n",
              "      <td>0.435897</td>\n",
              "      <td>-1443636648652872475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>39</td>\n",
              "      <td>48</td>\n",
              "      <td>88</td>\n",
              "      <td>0.443182</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>-2979881261169775358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>22</td>\n",
              "      <td>34</td>\n",
              "      <td>80</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>-3596626804281480007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>24</td>\n",
              "      <td>32</td>\n",
              "      <td>73</td>\n",
              "      <td>0.328767</td>\n",
              "      <td>0.438356</td>\n",
              "      <td>1116121227607581999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>16</td>\n",
              "      <td>21</td>\n",
              "      <td>69</td>\n",
              "      <td>0.231884</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>692689608292948411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>20</td>\n",
              "      <td>28</td>\n",
              "      <td>69</td>\n",
              "      <td>0.289855</td>\n",
              "      <td>0.405797</td>\n",
              "      <td>-9016528795238256703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>23</td>\n",
              "      <td>30</td>\n",
              "      <td>68</td>\n",
              "      <td>0.338235</td>\n",
              "      <td>0.441176</td>\n",
              "      <td>3636910968448833585</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     hits@5_count  hits@10_count  ...  recall@10           _person_id\n",
              "76             21             45  ...   0.234375  3609194402293569455\n",
              "17             30             56  ...   0.417910 -2626634673110551643\n",
              "16             16             34  ...   0.261538 -1032019229384696495\n",
              "10             38             51  ...   0.435897 -1443636648652872475\n",
              "82             39             48  ...   0.545455 -2979881261169775358\n",
              "161            22             34  ...   0.425000 -3596626804281480007\n",
              "65             24             32  ...   0.438356  1116121227607581999\n",
              "81             16             21  ...   0.304348   692689608292948411\n",
              "106            20             28  ...   0.405797 -9016528795238256703\n",
              "52             23             30  ...   0.441176  3636910968448833585\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5MytJa_8HdM",
        "colab_type": "text"
      },
      "source": [
        "# Comparing the two models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9ZJAJDg741f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "7e990247-8472-4547-da1b-91d04e10e0a2"
      },
      "source": [
        "global_metrics_df = pd.DataFrame([cb_global_metrics, pop_global_metrics, cf_global_metrics]) \\\n",
        "                        .set_index('modelName')\n",
        "global_metrics_df"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recall@5</th>\n",
              "      <th>recall@10</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modelName</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Content-Based</th>\n",
              "      <td>0.162874</td>\n",
              "      <td>0.261442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Popularity</th>\n",
              "      <td>0.241754</td>\n",
              "      <td>0.372923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Collaborative Filtering</th>\n",
              "      <td>0.334058</td>\n",
              "      <td>0.468167</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         recall@5  recall@10\n",
              "modelName                                   \n",
              "Content-Based            0.162874   0.261442\n",
              "Popularity               0.241754   0.372923\n",
              "Collaborative Filtering  0.334058   0.468167"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lgclcjff8VXA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "11e28441-44ab-4e04-8c82-0e7d6bec85ec"
      },
      "source": [
        "%matplotlib inline\n",
        "ax = global_metrics_df.transpose().plot(kind='bar', figsize=(15,8))\n",
        "for p in ax.patches:\n",
        "    ax.annotate(\"%.3f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAH6CAYAAAB20r9hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzde1TVVf7/8dcWUDPTnNSZETBUTAGBgx68pJZoillfuowaliOONeosm66j2Xy/KfnrYn0ds75WTn0rXaOJZZqUaWVqXioBlVDRwhQTtFKbvOYF2r8/tPMVwSQFzkaej7Va63z23p/9eX/OYnV6tT8XY60VAAAAAMAdtfxdAAAAAACgJIIaAAAAADiGoAYAAAAAjiGoAQAAAIBjCGoAAAAA4BiCGgAAAAA4JtBfB27cuLENCwvz1+EBAAAAwK/Wrl2711rbpKw+vwW1sLAwZWVl+evwAAAAAOBXxpgdZ+vj0kcAAAAAcAxBDQAAAAAcQ1ADAAAAAMf47R61spw4cUIFBQU6evSov0tBNVW3bl2FhIQoKCjI36UAAAAA582poFZQUKDLLrtMYWFhMsb4uxxUM9Za7du3TwUFBWrRooW/ywEAABeBxYsX695771VxcbHuuusujR07tsxxb731lvr376/MzEx5vV5JUk5OjkaMGKEDBw6oVq1ayszMVN26dTV79mw98cQTMsaoWbNmmjlzpho3blyVp4VqwKlLH48ePaorrriCkIbzYozRFVdcwYosAACoEMXFxRo1apQWLVqk3NxczZ49W7m5uaXGHTx4UM8++6w6derkaysqKtLgwYM1bdo0bdq0ScuXL1dQUJCKiop07733atmyZcrJyVFMTIymTp1alaeFasKpoCaJkIYLwt8PAACoKBkZGQoPD1fLli1Vu3ZtJScna8GCBaXGPfLII3rooYdUt25dX9sHH3ygmJgYxcbGSpKuuOIKBQQEyFora60OHz4sa60OHDigZs2aVdk5ofpwLqjVVGFhYdq7d2+5xxhj9OCDD/r6Jk2apNTU1MosEQAAoEYpLCxUaGiobzskJESFhYUlxqxbt047d+7UDTfcUKL9yy+/lDFGiYmJat++vZ5++mlJUlBQkF588UVFR0erWbNmys3N1Z133ln5J4Nqh6BWTdWpU0fz5s07Z7gDAABA5fjpp5/0wAMP6B//+EepvqKiIq1atUqzZs3SqlWrNH/+fH300Uc6ceKEXnzxRa1fv167du1STEyMnnzyST9UD9cR1C5Afn6+2rZtq6FDh+qqq67SHXfcoSVLlqhr165q3bq1MjIy9P333+vmm29WTEyMOnfurJycHEnSvn371KdPH0VFRemuu+6StdY378yZM9WxY0d5PB6NGDFCxcXFpY4dGBio4cOH65lnninV984776hTp06Ki4vTddddp2+//VaSlJqaqpSUFHXv3l1XXnml5s2bpzFjxig6Olp9+/bViRMnJElr167Vtddeqw4dOigxMVG7d++ujK8PAADAacHBwdq5c6dvu6CgQMHBwb7tgwcPauPGjerRo4fCwsL02WefKSkpSVlZWQoJCdE111yjxo0bq169eurXr5/WrVun7OxsSVKrVq1kjNHAgQP1ySefVPm5wX0EtQu0detWPfjgg9qyZYu2bNmi119/XatWrdKkSZP0xBNPaPz48YqLi1NOTo6eeOIJDRkyRJL06KOPqlu3btq0aZNuueUWff3115KkzZs3a86cOVq9erWys7MVEBCgWbNmlXnsUaNGadasWdq/f3+J9m7duumzzz7T+vXrlZyc7Ftql6SvvvpKS5cuVXp6ugYPHqyEhARt2LBBl1xyiRYuXKgTJ07or3/9q+bOnau1a9dq2LBh+s///M9K+vYAAADcFR8fr7y8PG3fvl3Hjx9XWlqakpKSfP0NGzbU3r17lZ+fr/z8fHXu3Fnp6enyer1KTEzUhg0bdOTIERUVFenjjz9WZGSkgoODlZubqz179kiSPvzwQ0VERPjrFOEwpx7PXx21aNFC0dHRkqSoqCj16tVLxhhFR0crPz9fO3bs0FtvvSVJ6tmzp/bt26cDBw5oxYoVmjdvniTphhtuUKNGjSRJH330kdauXav4+HhJ0o8//qimTZuWeewGDRpoyJAheu6553TJJZf42gsKCnTbbbdp9+7dOn78eIlH1V9//fUKCgpSdHS0iouL1bdvX0ny1fvFF19o48aN6t27t6STTzv6/e9/X5FfGQAAQLUQGBioqVOnKjExUcXFxRo2bJiioqI0btw4eb3eEqHtTI0aNdIDDzyg+Ph4GWPUr18/331s48eP1zXXXKOgoCBdeeWVmj59ehWdEaoTgtoFqlOnju9zrVq1fNu1atVSUVHRr37xsrVWKSkp5b5W+b777lP79u31pz/9ydf217/+VQ888ICSkpK0fPnyEg8ZOb2+oKAg31MSf67XWquoqCh9+umnv6puAACAi1G/fv3Ur1+/Em0TJkwoc+zy5ctLbA8ePFiDBw8uNW7kyJEaOXJkhdWIixOXPlay7t27+y5dXL58uRo3bqwGDRrommuu0euvvy5JWrRokf79739Lknr16qW5c+fqu+++kyR9//332rFjx1nn/81vfqOBAwfqlVde8bXt37/fd/30jBkzflW9bdq00Z49e3xB7cSJE9q0adOvmgMAAADAhSGoVbLU1FStXbtWMTExGjt2rC84jR8/XitWrFBUVJTmzZun5s2bS5IiIyP12GOPqU+fPoqJiVHv3r3P+TCPBx98sMTTH1NTUzVgwAB16NDhV7/lvnbt2po7d64eeughxcbGyuPxcIMrAAAAUMXM6U8brEper9dmZWWVaNu8eTM3U+KC8XcEAACA6sAYs9Za6y2rjxU1AAAAAHAMQQ0AAAAAHENQAwAAAADH8Hh+AAAAVHvRM6L9XYJzNqRs8HcJuACsqAEAAACAYwhqAAAAAOAYgloZvvnmGyUnJ6tVq1bq0KGD+vXrpy+//PJXzzNlyhQdOXLkvOtYvnz5Wd9htnz5cjVs2FAej0cxMTG67rrrfC/JrgzTp0/X3XffXWnzAwAAAPg/Tt+jFjZ2YYXOlz/xhnOOsdbqlltuUUpKitLS0iRJn3/+ub799ltdddVVv+p4U6ZM0eDBg1WvXr3zqnf58uWqX7++rr766jL7u3fvrnfffVeS9PDDD+v555/Xo48+el7HAgAAAOAOVtTOsGzZMgUFBWnkyJG+ttjYWHXr1k2jR49Wu3btFB0drTlz5kg6GaZ69Oih/v37q23btrrjjjtkrdVzzz2nXbt2KSEhQQkJCZKkDz74QF26dFH79u01YMAAHTp0SJIUFham8ePHq3379oqOjtaWLVuUn5+vadOm6ZlnnpHH49HKlSvPWrO1VgcPHlSjRo0kSRkZGerSpYvi4uJ09dVX64svvpAkbdq0SR07dvStwuXl5UmSZs6c6WsfMWKEiouLJUmvvfaarrrqKnXs2FGrV6+u4G8aAAAAwNkQ1M6wceNGdejQoVT7vHnzlJ2drc8//1xLlizR6NGjtXv3bknS+vXrNWXKFOXm5mrbtm1avXq17rnnHjVr1kzLli3TsmXLtHfvXj322GNasmSJ1q1bJ6/Xq8mTJ/vmb9y4sdatW6e//OUvmjRpksLCwjRy5Ejdf//9ys7OVvfu3UvVtHLlSnk8HjVv3lxLlizRsGHDJElt27bVypUrtX79ek2YMEF///vfJUnTpk3Tvffeq+zsbGVlZSkkJESbN2/WnDlztHr1amVnZysgIECzZs3S7t27NX78eK1evVqrVq1Sbm5uZXzdAAAAAMrg9KWPLlm1apUGDRqkgIAA/fa3v9W1116rzMxMNWjQQB07dlRISIgkyePxKD8/X926dSux/2effabc3Fx17dpVknT8+HF16dLF13/rrbdKkjp06KB58+aVq6bTL3186qmnNGbMGE2bNk379+9XSkqK8vLyZIzRiRMnJEldunTR448/roKCAt16661q3bq1PvroI61du1bx8fGSpB9//FFNmzbVmjVr1KNHDzVp0kSSdNttt53XfXoAAAAAfj2C2hmioqI0d+7cX7VPnTp1fJ8DAgJUVFRUaoy1Vr1799bs2bN/cY6z7V9cXOxb6UtKSlLPnj1L9CclJekPf/iDJOmRRx5RQkKC5s+fr/z8fPXo0UOSdPvtt6tTp05auHCh+vXrp3/+85+y1iolJUVPPvlkifnefvvtcp49AAAAgIrGpY9n6Nmzp44dO6aXXnrJ15aTk6PLL79cc+bMUXFxsfbs2aMVK1aoY8eOvzjXZZddpoMHD0qSOnfurNWrV2vr1q2SpMOHD59zher0/QMCApSdna3s7GxNmDCh1NhVq1apVatWkqT9+/crODhY0smnNf5s27Ztatmype655x7ddNNNysnJUa9evTR37lzfEyO///577dixQ506ddLHH3+sffv26cSJE3rzzTd/sVYAAAAAFYegdgZjjObPn68lS5aoVatWioqK0sMPP6zbb79dMTExio2NVc+ePfX000/rd7/73S/ONXz4cPXt21cJCQlq0qSJpk+frkGDBikmJkZdunTRli1bfnH///iP/9D8+fPP+jCRn+9Ri42N1b/+9S/94x//kCSNGTNGDz/8sOLi4kqszr3xxhtq166dPB6PNm7cqCFDhigyMlKPPfaY+vTpo5iYGPXu3Vu7d+/W73//e6WmpqpLly7q2rWrIiIizuPbBAAAAHA+jLXWLwf2er02KyurRNvmzZsJBLhg/B0BAFDzRM+I9ncJztmQssHfJeAcjDFrrbXesvpYUQMAAAAAxxDUAAAAAMAxBDUAAAAAcAxBDQAAAAAcQ1ADAAAAAMcQ1AAAAADAMQS1MwQEBMjj8ahdu3YaMGCAjhw5UqHz9+jRQ2e+luBcxo0bpyVLlkiSpkyZUuE1AQAAAHBLoL8L+EWpDSt4vv3nHHLJJZcoOztbknTHHXdo2rRpeuCBByq2jl+huLhYEyZM8G1PmTJFgwcPVr169fxWEwAAAIDKxYraL+jevbu2bt2q77//XjfffLNiYmLUuXNn5eTkSJJSU1P1xz/+UV26dFHr1q318ssvS5KWL1+uG2+80TfP3XffrenTp5ea/y9/+Yu8Xq+ioqI0fvx4X3tYWJgeeughtW/fXm+++aaGDh2quXPn6rnnntOuXbuUkJCghIQEvfrqq7rvvvt8+7388su6//77K+nbAAAAAFBVCGpnUVRUpEWLFik6Olrjx49XXFyccnJy9MQTT2jIkCG+cTk5OVq6dKk+/fRTTZgwQbt27Sr3MR5//HFlZWUpJydHH3/8sS8AStIVV1yhdevWKTk52dd2zz33qFmzZlq2bJmWLVumgQMH6p133tGJEyckSa+99pqGDRtWAWcPAAAAwJ8Iamf48ccf5fF45PV61bx5c915551atWqV/vjHP0qSevbsqX379unAgQOSpJtuukmXXHKJGjdurISEBGVkZJT7WG+88Ybat2+vuLg4bdq0Sbm5ub6+22677Zz7169fXz179tS7776rLVu26MSJE4qOjv6VZwwAAADANW7fo+YHp9+jVh7GmFLbgYGB+umnn3xtR48eLbXf9u3bNWnSJGVmZqpRo0YaOnRoiXGXXnppuY5/11136YknnlDbtm31pz/9qdx1AwAAAHAXK2rl0L17d82aNUvSyfvPGjdurAYNGkiSFixYoKNHj2rfvn1avny54uPjdeWVVyo3N1fHjh3TDz/8oI8++qjUnAcOHNCll16qhg0b6ttvv9WiRYvKVctll12mgwcP+rY7deqknTt36vXXX9egQYMq4GwBAAAA+BsrauWQmpqqYcOGKSYmRvXq1dOMGTN8fTExMUpISNDevXv1yCOPqFmzZpKkgQMHql27dmrRooXi4uJKzRkbG6u4uDi1bdtWoaGh6tq1a7lqGT58uPr27eu7V+3nY2VnZ6tRo0YVcLYAAAAA/M1Ya/1yYK/Xa898n9jmzZsVERHhl3rOR2pqqurXr6+//e1vfq3jxhtv1P33369evXr5tQ5XVLe/IwAAcOGiZ3Cf/pk2pGzwdwk4B2PMWmutt6w+Ln2sxn744QddddVVuuSSSwhpAAAAwEWESx8vQGpqql+Pf/nll+vLL7/0aw0AAAAAKh4ragAAAADgGIIaAAAAADiGoAYAAAAAjiGoAQAAAIBjCGpn+Oabb5ScnKxWrVqpQ4cO6tev3y8+sCM/P1/t2rWTdPJl2DfeeOMvzj99+nTdfffdFVrzz6ZMmaIjR474tvv166cffvjhgucNCwtTdHS0PB6PPB6PPvnkkxJz169fX9LJ7+L1118/r2NcffXVF1wnAAAAcLFw+qmPFf0+jHO9S8Jaq1tuuUUpKSlKS0uTJH3++ef69ttvddVVV1VoLefDWitrrWrVKjtfT5kyRYMHD1a9evUkSe+9916FHXvZsmVq3Lixb7usuX8Oarfffnu55y0qKlJgYKA++eSTCqkTAAAAuBiwonaaZcuWKSgoSCNHjvS1xcbGqnv37rLWavTo0WrXrp2io6M1Z86cX5wrIyNDXbp0UVxcnK6++mp98cUXvr6dO3eqR48eat26tR599FFf++TJk9WuXTu1a9dOU6ZMkXQy/LRp00ZDhgxRu3bttHPnTv3lL3+R1+tVVFSUxo8fL0l67rnntGvXLiUkJCghIUHSyZWwvXv3auzYsXr++ed9x0lNTdWkSZMkSf/93/+t+Ph4xcTE+OYqj5/nPt3YsWO1cuVKeTwePfPMMyouLtbo0aN98//zn/+UdHLlsXv37kpKSlJkZKSk/1uVW758uXr06KH+/furbdu2uuOOO/TzS9nfe+89tW3bVh06dNA999xzztVLAAAAoLpyekWtqm3cuFEdOnQos2/evHnKzs7W559/rr179yo+Pl7XXHPNWedq27atVq5cqcDAQC1ZskR///vf9dZbb0k6GeI2btyoevXqKT4+XjfccIOMMXrttde0Zs0aWWvVqVMnXXvttWrUqJHy8vI0Y8YMde7cWZL0+OOP6ze/+Y2Ki4vVq1cv5eTk6J577tHkyZNLrXxJ0m233ab77rtPo0aNkiS98cYbev/99/XBBx8oLy9PGRkZstYqKSlJK1asKPO8EhISFBAQoDp16mjNmjVlnvPEiRM1adIkvfvuu5Kkl156SQ0bNlRmZqaOHTumrl27qk+fPpKkdevWaePGjWrRokWpedavX69NmzapWbNm6tq1q1avXi2v16sRI0ZoxYoVatGihQYNGnTW7x4AAACo7ghq5bRq1SoNGjRIAQEB+u1vf6trr71WmZmZiomJKXP8/v37lZKSory8PBljdOLECV9f7969dcUVV0iSbr31Vq1atUrGGN1yyy269NJLfe0rV65UUlKSrrzySl9Ik04GrZdeeklFRUXavXu3cnNzz1qHJMXFxem7777Trl27tGfPHjVq1EihoaF69tln9cEHHyguLk6SdOjQIeXl5ZUZ1MoKgOfywQcfKCcnR3PnzvV9J3l5eapdu7Y6duxYZkiTpI4dOyokJESS5PF4lJ+fr/r166tly5a+fQYNGqSXXnrpV9UDAAAAVBcEtdNERUX5QsWFeuSRR5SQkKD58+crPz9fPXr08PUZY0qMPXP7TD+HN0navn27Jk2apMzMTDVq1EhDhw7V0aNHz1nPgAEDNHfuXH3zzTe67bbbJJ285+3hhx/WiBEjfsWZlZ+1Vv/zP/+jxMTEEu3Lly8vcU5nqlOnju9zQECAioqKKqU+AAAAwFXco3aanj176tixYyVWanJycrRy5Up1795dc+bMUXFxsfbs2aMVK1aoY8eOZ51r//79Cg4OlnTySY+n+/DDD/X999/rxx9/1Ntvv62uXbuqe/fuevvtt3XkyBEdPnxY8+fPV/fu3UvNe+DAAV166aVq2LChvv32Wy1atMjXd9lll+ngwYNl1nPbbbcpLS1Nc+fO1YABAyRJiYmJevXVV3Xo0CFJUmFhob777rvyfVllOPP4iYmJevHFF32riV9++aUOHz58XnO3adNG27ZtU35+viSd8x5BAAAAoDpjRe00xhjNnz9f9913n5566inVrVtXYWFhmjJlirp166ZPP/1UsbGxMsbo6aef1u9+9ztfcDjTmDFjlJKSoscee0w33HBDib6OHTvqD3/4gwoKCjR48GB5vV5J0tChQ33h76677lJcXFyp+WNjYxUXF6e2bdsqNDRUXbt29fUNHz5cffv2VbNmzbRs2bIS+0VFRengwYMKDg7W73//e0lSnz59tHnzZnXp0kXSyQd6zJw5U02bNj2v7y8mJkYBAQGKjY3V0KFDde+99yo/P1/t27eXtVZNmjTR22+/fV5zX3LJJXrhhRfUt29fXXrppYqPjz+veQAAAIDqwPz8RL2q5vV6bVZWVom2zZs3KyIiwi/1wH2HDh1S/fr1Za3VqFGj1Lp1a91///2lxvF3BABAzVPRr3W6GJzr1VTwP2PMWmutt6w+Ln1EtfHyyy/L4/EoKipK+/fvr7R76wAAAAB/49JHVBv3339/mStoAAAAwMWGFTUAAAAAcIxzQc1f98zh4sDfDwAAAC4GTgW1unXrat++ffzHNs6LtVb79u1T3bp1/V0KAAAAcEGcukctJCREBQUF2rNnj79LQTVVt25dhYSE+LsMAAAA4II4FdSCgoLUokULf5cBAAAAAH7l1KWPAAAAAACCGgAAAAA4h6AGAAAAAI4hqAEAAACAYwhqAAAAAOAYghoAAAAAOIagBgAAAACOKVdQM8b0NcZ8YYzZaowZ+wvj/mCMscYYb8WVCAAAAAA1yzmDmjEmQNLzkq6XFClpkDEmsoxxl0m6V9Kaii4SAAAAAGqS8qyodZS01Vq7zVp7XFKapJvKGPf/JD0l6WgF1gcAAAAANU55glqwpJ2nbRecavMxxrSXFGqtXViBtQEAAABAjXTBDxMxxtSSNFnSg+UYO9wYk2WMydqzZ8+FHhoAAAAALkrlCWqFkkJP2w451fazyyS1k7TcGJMvqbOk9LIeKGKtfcla67XWeps0aXL+VQMAAADARaw8QS1TUmtjTAtjTG1JyZLSf+601u631ja21oZZa8MkfSYpyVqbVSkVAwAAAMBF7pxBzVpbJOluSe9L2izpDWvtJmPMBGNMUmUXCAAAAAA1TWB5Bllr35P03hlt484ytseFlwUAAAAANdcFP0wEAAAAAFCxCGoAAAAA4BiCGgAAAAA4hqAGAAAAAI4hqAEAAECLFy9WmzZtFB4erokTJ5bqnzZtmqKjo+XxeNStWzfl5uZKkmbNmiWPx+P7p1atWsrOzpYk9e3bV7GxsYqKitLIkSNVXFxcpecEVGfGWuuXA3u9XpuVxavWAAAA/K24uFhXXXWVPvzwQ4WEhCg+Pl6zZ89WZGSkb8yBAwfUoEEDSVJ6erpeeOEFLV68uMQ8GzZs0M0336yvvvqqxD7WWvXv318DBgxQcnJypZxD9IzoSpm3OtuQssHfJeAcjDFrrbXesvpYUQMAAKjhMjIyFB4erpYtW6p27dpKTk7WggULSoz5OaRJ0uHDh2WMKTXP7NmzSwSxn/cpKirS8ePHy9wHQNkIagAAADVcYWGhQkNDfdshISEqLCwsNe75559Xq1atNGbMGD333HOl+ufMmaNBgwaVaEtMTFTTpk112WWXqX///hVfPHCRIqgBAACgXEaNGqWvvvpKTz31lB577LESfWvWrFG9evXUrl27Eu3vv/++du/erWPHjmnp0qVVWS5QrRHUAAAAarjg4GDt3LnTt11QUKDg4OCzjk9OTtbbb79doi0tLa3UatrP6tatq5tuuqnU5ZQAzo6gBgAAUMPFx8crLy9P27dv1/Hjx5WWlqakpKQSY/Ly8nyfFy5cqNatW/u2f/rpJ73xxhsl7k87dOiQdu/eLenkPWoLFy5U27ZtK/lMgItHoL8LAAAAgH8FBgZq6tSpSkxMVHFxsYYNG6aoqCiNGzdOXq9XSUlJmjp1qpYsWaKgoCA1atRIM2bM8O2/YsUKhYaGqmXLlr62w4cPKykpSceOHdNPP/2khIQEjRw50h+nB1RLPJ4fAAAA1R6P5y+Nx/O7j8fzAwAAAEA1QlADAAAAAMcQ1AAAAADAMQQ1AAAAAHAMQQ0AAAAAHENQAwAAAADH8B41AACA6iS1ob8rcFOL5v6uAKhQrKgBAAAAgGMIagAAAADgGIIaAAAAADiGoAYAAAAAjiGoAQAAAIBjCGoAAAAA4BiCGgAAAAA4hqAGAAAAAI4hqAEAAACAYwhqAAAAAOAYghoAAAAAOIagBgAAAACOIagBAAAAgGMIagAAAADgGIIaAAAAADiGoAYAAAAAjiGoAQAAAIBjCGoAAAAA4BiCGgAAAAA4hqAGwGmLFy9WmzZtFB4erokTJ5bqnzZtmqKjo+XxeNStWzfl5uZKkjIyMuTxeOTxeBQbG6v58+eX2K+4uFhxcXG68cYbq+Q8AAAAfg2CGgBnFRcXa9SoUVq0aJFyc3M1e/ZsXxD72e23364NGzYoOztbY8aM0QMPPCBJateunbKyspSdna3FixdrxIgRKioq8u337LPPKiIiokrPBwAAoLwIagCclZGRofDwcLVs2VK1a9dWcnKyFixYUGJMgwYNfJ8PHz4sY4wkqV69egoMDJQkHT161NcuSQUFBVq4cKHuuuuuKjgLAACAXy/Q3wUAwNkUFhYqNDTUtx0SEqI1a9aUGvf8889r8uTJOn78uJYuXeprX7NmjYYNG6YdO3boX//6ly+43XfffXr66ad18ODByj8JAACA88CKGoBqb9SoUfrqq6/01FNP6bHHHvO1d+rUSZs2bVJmZqaefPJJHT16VO+++66aNm2qDh06+LFiAACAX0ZQA+Cs4OBg7dy507ddUFCg4ODgs45PTk7W22+/Xao9IiJC9evX18aNG7V69Wqlp6crLCxMycnJWrp0qQYPHlwp9QMAAJwvghoAZ8XHxysvL0/bt2/X8ePHlZaWpqSkpBJj8vLyfJ8XLlyo1q1bS5K2b9/ue3jIjh07tGXLFoWFhenJJ59UQUGB8vPzlZaWpp49e2rmzNu6/IQAABuBSURBVJlVd1IAAADlwD1qAJwVGBioqVOnKjExUcXFxRo2bJiioqI0btw4eb1eJSUlaerUqVqyZImCgoLUqFEjzZgxQ5K0atUqTZw4UUFBQapVq5ZeeOEFNW7c2M9nBAAAUD7GWuuXA3u9XpuVleWXYwMAAFRbqQ39XYGTols093cJztmQssHfJeAcjDFrrbXesvq49BEAAAAAHENQAwAAAADHENQAAAAAwDEENQAAAABwDEENAAAAABzD4/kBXLDoGdH+LsFJPG0LAACcL1bUAAAAAMAxBDUAAAAAcAxBDQAAAAAcQ1ADAAAAAMcQ1AAAAADAMQQ1AAAAAHAMQQ0AAAAAHENQAwAAAADHENQAAAAAwDEENQAAAABwDEENAAAAABxDUAMAAAAAxxDUAAAAAMAxBDUAAAAAcAxBDQAAAAAcQ1ADAAAAAMcQ1AAAAADAMQQ1AAAAAHAMQQ0AAAAAHENQAwAAAADHENQAAAAAwDEENQAAAABwDEENAAAAABxDUAMAAAAAxxDUAAAAAMAxBDUAAAAAcEy5gpoxpq8x5gtjzFZjzNgy+kcaYzYYY7KNMauMMZEVXyoAAAAA1AznDGrGmABJz0u6XlKkpEFlBLHXrbXR1lqPpKclTa7wSgEAAACghijPilpHSVuttdustcclpUm66fQB1toDp21eKslWXIkAAAAAULMElmNMsKSdp20XSOp05iBjzChJD0iqLalnWRMZY4ZLGi5JzZs3/7W1AgAAAECNUGEPE7HWPm+tbSXpIUn/dZYxL1lrvdZab5MmTSrq0AAAAABwUSlPUCuUFHradsiptrNJk3TzhRQFAAAAADVZeYJapqTWxpgWxpjakpIlpZ8+wBjT+rTNGyTlVVyJAAAAAFCznPMeNWttkTHmbknvSwqQ9Kq1dpMxZoKkLGttuqS7jTHXSToh6d+SUiqzaAAAAAC4mJXnYSKy1r4n6b0z2sad9vneCq4LAAAAAGqsCnuYCAAAAACgYhDUAAAAAMAxBDUAAAAAcAxBDQAAAAAcQ1ADAAAAAMcQ1AAAAADAMQQ1AAAAAHAMQQ0AAAAAHENQAwAAAADHENQAAAAAwDEENQAAAABwDEENAAAAABxDUAMAAAAAxxDUAAAAAMAxBDUAAFCjLF68WG3atFF4eLgmTpxYqn/y5MmKjIxUTEyMevXqpR07dvj6vv76a/Xp00cRERGKjIxUfn6+JGnq1KkKDw+XMUZ79+6tqlMBcBEjqAEAgBqjuLhYo0aN0qJFi5Sbm6vZs2crNze3xJi4uDhlZWUpJydH/fv315gxY3x9Q4YM0ejRo7V582ZlZGSoadOmkqSuXbtqyZIluvLKK6v0fABcvAhqAACgxsjIyFB4eLhatmyp2rVrKzk5WQsWLCgxJiEhQfXq1ZMkde7cWQUFBZKk3NxcFRUVqXfv3pKk+vXr+8bFxcUpLCys6k4EwEWPoAYAAGqMwsJChYaG+rZDQkJUWFh41vGvvPKKrr/+eknSl19+qcsvv1y33nqr4uLiNHr0aBUXF1d6zQBqJoIaAABAGWbOnKmsrCyNHj1aklRUVKSVK1dq0qRJyszM1LZt2zR9+nT/FgngokVQAwAANUZwcLB27tzp2y4oKFBwcHCpcUuWLNHjjz+u9PR01alTR9LJ1TePx6OWLVsqMDBQN998s9atW1dltQOoWQhqAACgxoiPj1deXp62b9+u48ePKy0tTUlJSSXGrF+/XiNGjFB6errvYSE/7/vDDz9oz549kqSlS5cqMjKySusHUHMQ1AAAQI0RGBioqVOnKjExURERERo4cKCioqI0btw4paenS5JGjx6tQ4cOacCAAfJ4PL4gFxAQoEmTJqlXr16Kjo6WtVZ//vOfJUnPPfecQkJCVFBQoJiYGN11111+O0cAFwdjrfXLgb1er83KyvLLsQFUrOgZ0f4uwUkbUjb4uwQAF6PUhv6uwEnRLZr7uwTn8DvkPmPMWmutt6w+VtQAAAAAwDEENQAAAABwDEENAAAAABxDUAMAAAAAxxDUAAAAAMAxBDUAAAAAcEygvwsAAAAoS9jYhf4uwUn5df1dAYCqwIoaAAAAADiGoAY4YvHixWrTpo3Cw8M1ceLEUv2TJ09WZGSkYmJi1KtXL+3YsaNE/4EDBxQSEqK7775bknTkyBHdcMMNatu2raKiojR27NgqOQ8AAABcOIIa4IDi4mKNGjVKixYtUm5urmbPnq3c3NwSY+Li4pSVlaWcnBz1799fY8aMKdH/yCOP6JprrinR9re//U1btmzR+vXrtXr1ai1atKjSzwUAAAAXjqAGOCAjI0Ph4eFq2bKlateureTkZC1YsKDEmISEBNWrV0+S1LlzZxUUFPj61q5dq2+//VZ9+vTxtdWrV08JCQmSpNq1a6t9+/Yl9gEAAIC7CGqAAwoLCxUaGurbDgkJUWFh4VnHv/LKK7r++uslST/99JMefPBBTZo06azjf/jhB73zzjvq1atXxRUNAACASsNTH4FqZubMmcrKytLHH38sSXrhhRfUr18/hYSElDm+qKhIgwYN0j333KOWLVtWZakAAAA4TwQ1wAHBwcHauXOnb7ugoEDBwcGlxi1ZskSPP/64Pv74Y9WpU0eS9Omnn2rlypV64YUXdOjQIR0/flz169f3PZBk+PDhat26te67776qORkAAABcMIIa4ID4+Hjl5eVp+/btCg4OVlpaml5//fUSY9avX68RI0Zo8eLFatq0qa991qxZvs/Tp09XVlaWL6T913/9l/bv36///d//rZoTAQAAQIXgHjXAAYGBgZo6daoSExMVERGhgQMHKioqSuPGjVN6erokafTo0Tp06JAGDBggj8ejpKSkX5yzoKBAjz/+uHJzc9W+fXt5PB4CGwAAQDVhrLV+ObDX67VZWVl+OTaAihU9I9rfJThpQ8oGf5cAVGthYxf6uwQn5de93d8lOCm6RXN/l+AcfofcZ4xZa631ltXHihoAAAAAOIagBgAAAACOIagBAAAAgGMIagAAAADgGIIaAAAAADiGoAYAAAAAjuGF18CvkdrQ3xW4iUciAwAAVChW1AAAAADAMQQ1AAAAAHAMQQ0AAAAAHENQAwAAAADHENQAAAAAwDEENQAAAABwDEENAAAAABxDUAMAAAAAxxDUAAAAAMAxBDUAAAAAcAxBDQAAAAAcQ1ADAAAAAMcQ1AAAAADAMQQ1AAAAAHAMQQ0AAAAAHENQAwAAAADHENQAAAAAwDEENQAAAABwDEENAAAAABxDUAMAAAAAxxDUAAAAAMAxBDUAAAAAcAxBDQAAAAAcQ1ADAAAAAMcQ1AAAAADAMQQ1AAAAAHAMQQ0AAAAAHENQAwAAAADHENQAAAAAwDEENQAAAABwDEENAAAAABxDUAMAAAAAx5QrqBlj+hpjvjDGbDXGjC2j/wFjTK4xJscY85Ex5sqKLxUAAAAAaoZzBjVjTICk5yVdLylS0iBjTOQZw9ZL8lprYyTNlfR0RRcKAAAAADVFeVbUOkraaq3dZq09LilN0k2nD7DWLrPWHjm1+ZmkkIotEwAAAABqjvIEtWBJO0/bLjjVdjZ3Slp0IUUBAAAAQE0WWJGTGWMGS/JKuvYs/cMlDZek5s2bV+ShAQAAAOCiUZ4VtUJJoadth5xqK8EYc52k/5SUZK09VtZE1tqXrLVea623SZMm51MvAAAAAFz0yhPUMiW1Nsa0MMbUlpQsKf30AcaYOEn/1MmQ9l3FlwkAAAAANcc5g5q1tkjS3ZLel7RZ0hvW2k3GmAnGmKRTw/5bUn1Jbxpjso0x6WeZDgAAAABwDuW6R81a+56k985oG3fa5+squC4AAAAAqLHK9cJrAAAAAEDVIagBAAAAgGMIagAAAADgGIIaAAAAADiGoAYAAAAAjiGoAQAAAIBjCGoAAAAA4BiCGgAAAAA4hqAGAAAAAI4hqAEAAACAYwhqAAAAAOAYghoAAAAAOIagBgAAAACOIaihyi1evFht2rRReHi4Jk6cWKp/xYoVat++vQIDAzV37twSfV9//bX69OmjiIgIRUZGKj8/X5J05513KjY2VjExMerfv78OHTpUFacCAAAAVAqCGqpUcXGxRo0apUWLFik3N1ezZ89Wbm5uiTHNmzfX9OnTdfvtt5faf8iQIRo9erQ2b96sjIwMNW3aVJL0zDPP6PPPP1dOTo6aN2+uqVOnVsn5AAAAAJUh0N8FoGbJyMhQeHi4WrZsKUlKTk7WggULFBkZ6RsTFhYmSapVq+T/R8jNzVVRUZF69+4tSapfv76vr0GDBpIka61+/PFHGWMq8zQAAACASsWKGqpUYWGhQkNDfdshISEqLCws175ffvmlLr/8ct16662Ki4vT6NGjVVxc7Ov/05/+pN/97nfasmWL/vrXv1Z47QAAAEBVIaih2igqKtLKlSs1adIkZWZmatu2bZo+fbqv/7XXXtOuXbsUERGhOXPm+K9QAAAA4AIR1FClgoODtXPnTt92QUGBgoODy7VvSEiIPB6PWrZsqcDAQN18881at25diTEBAQFKTk7WW2+9VaF1AwAAAFWJoIYqFR8fr7y8PG3fvl3Hjx9XWlqakpKSyr3vDz/8oD179kiSli5dqsjISFlrtXXrVkkn71FLT09X27ZtK+0cAAAAgMpGUEOVCgwM1NSpU5WYmKiIiAgNHDhQUVFRGjdunNLT0yVJmZmZCgkJ0ZtvvqkRI0YoKipK0snVskmTJqlXr16Kjo6WtVZ//vOfZa1VSkqKoqOjFR0drd27d2vcuHH+PE0AAADgghhrrV8O7PV6bVZWll+ODZy31Ib+rsBJ0S2a+7sEJ21I2eDvEoBqLWzsQn+X4KT8uqVfXwN+i8rC75D7jDFrrbXesvpYUQMAAAAAxxDUAAAAAMAxBDUAAAAAcAxBDQAAAAAcQ1ADAAAAAMcQ1AAAAADAMYH+LgDu4rHIpeXX9XcFAAAAqAlYUQMAAAAAxxDUAAAAAMAxBDUAAAAAcAxBDQAAAAAcQ1ADAAAAAMcQ1AAAAADAMQQ1AAAAAHAMQQ0AAAAAHENQAwAAAADHENQAAAAAwDEENQAAAABwDEENAAAAABxDUAMAAAAAxxDUAAAAAMAxBDUAAAAAcAxBDQAAAAAcQ1ADAAAAAMcQ1AAAAADAMQQ1AAAAAHAMQQ0AAAAAHENQAwAAAADHENQAAAAAwDEENQAAAABwDEENAAAAABxDUAMAAAAAxxDUAAAAAMAxBDUAAAAAcAxBDQAAAAAcQ1ADAAAAAMcQ1AAAAADAMQQ1AAAAAHAMQQ0AAAAAHENQAwAAAADHENQAAAAAwDEENQAAAABwDEENAAAAABxDUAMAAAAAxxDUAAAAAMAxBDUAAAAAcAxBDQAAAAAcQ1ADAAAAAMcQ1AAAAADAMQQ1AAAAAHAMQQ0AAAAAHENQAwAAAADHENQAAAAAwDEENQAAAABwDEENAAAAABxDUAMAAAAAxxDUAAAAAMAxBDUAAAAAcEy5gpoxpq8x5gtjzFZjzNgy+q8xxqwzxhQZY/pXfJkAAAAAUHOcM6gZYwIkPS/pekmRkgYZYyLPGPa1pKGSXq/oAgEAAACgpgksx5iOkrZaa7dJkjEmTdJNknJ/HmCtzT/V91Ml1AgAAAAANUp5Ln0MlrTztO2CU22/mjFmuDEmyxiTtWfPnvOZAgAAAAAuelX6MBFr7UvWWq+11tukSZOqPDQAAAAAVBvlCWqFkkJP2w451QYAAAAAqATlCWqZklobY1oYY2pLSpaUXrllAQAAAEDNdc6gZq0tknS3pPclbZb0hrV2kzFmgjEmSZKMMfHGmAJJAyT90xizqTKLBgAAAICLWXme+ihr7XuS3jujbdxpnzN18pJIAAAAAMAFqtKHiQAAAAAAzo2gBgAAAACOIagBAAAAgGMIagAAAADgGIIaAAAAADiGoAYAAAAAjiGoAQAAAIBjCGoAAAAA4BiCGgAAAAA4hqAGAAAAAI4hqAEAAACAYwhqAAAAAOAYghoAAAAAOIagBgAAAACOIagBAAAAgGMIagAAAADgGIIaAAAAADiGoAYAAAAAjiGoAQAAAIBjCGoAAAAA4BiCGgAAAAA4hqAGAAAAAI4hqAEAAACAYwhqAAAAAOAYghoAAAAAOIagBgAAAACOIagBAAAAgGMIagAAAADgGIIaAAAAADiGoAYAAAAAjiGoAQAAAIBjCGoAAAAA4BiCGgAAAAA4hqAGAAAAAI4hqAEAAACAYwhqAAAAAOAYghoAAAAAOIagBgAAAACOIagBAAAAgGMIagAAAADgGIIaAAAAADiGoAYAAAAAjiGoAQAAAIBjCGoAAAAA4BiCGgAAAAA4hqAGAAAAAI4hqAEAAACAYwhqAAAAAOAYghoAAAAAOIagBgAAAACOIagBAAAAgGMIagAAAADgGIIaAAAAADiGoAYAAAAAjiGoAQAAAIBjCGoAAAAA4BiCGgAAAAA4hqAGAAAAAI4hqAEAAACAYwhqAAAAAOAYghoAAAAAOIagBgAAAACOIagBAAAAgGMIagAAAADgGIIaAAAAADiGoAYAAAAAjiGoAQAAAIBjCGoAAAAA4BiCGgAAAAA4hqAGAAAAAI4hqAEAAACAYwhqAAAAAOAYghoAAAAAOIagBgAAAACOIagBAAAAgGMIagAAAADgGIIaAAAAADiGoAYAAAAAjiGoAQAAAIBjyhXUjDF9jTFfGGO2GmPGltFfxxgz51T/GmNMWEUXCgAAAAA1xTmDmjEmQNLzkq6XFClpkDEm8oxhd0r6t7U2XNIzkp6q6EIBAAAAoKYoz4paR0lbrbXbrLXHJaVJuumMMTdJmnHq81xJvYwxpuLKBAAAAICaozxBLVjSztO2C061lTnGWlskab+kKyqiQAAAAACoaQKr8mDGmOGShp/aPGSM+aIqjw9cKMeWiRtL2uvvIk7a6O8CnGSGOvYXA+Ci4Ni/Wfgtchi/Q9XClWfrKE9QK5QUetp2yKm2ssYUGGMCJTWUtO/Miay1L0l6qRzHBHAOxpgsa63X33UAAGoufouAylOeSx8zJbU2xrQwxtSWlCwp/Ywx6ZJSTn3uL2mptdZWXJkAAAAAUHOcc0XNWltkjLlb0vuSAiS9aq3dZIyZICnLWpsu6RVJ/zLGbJX0vU6GOQAAAADAeTAsfAHVkzFm+KnLiQEA8At+i4DKQ1ADAAAAAMeU5x41AAAAAEAVIqgBAAAAgGMIagAAAADgmCp94TUAAACqN2OMkdRRUvCppkJJGbyaCahYrKgB1YQxpu9pnxsaY14xxuQYY143xvzWn7UBAGoGY0wfSXmSUiX1O/XPo5LyTvUBqCA89RGoJowx66y17U99/l9J30h6WdKtkq611t7sz/oAABc/Y8xmSddba/PPaG8h6T1rbYRfCgMuQlz6CFRPXmut59TnZ4wxKX6tBgBQUwRKKiijvVBSUBXXAlzUCGpA9dHUGPOAJCOpgTHGnHY/AJcxAwCqwquSMo0xaZJ2nmoLlZQs6f+3d3+hlpV1GMe/j1FkNqWTYyVEGJZlMWUZROlNkBIzFJISFFgY4VUDTYTUjQoVMWQXlVGUiZBSGFEiyfRHEIUIUalAbbooCWagAo3GGyWfLvY+TB48Nkf23uusvb4f2Jy91toXz82G/Tvvu55102CppDXk1kdpJJJcu+nUt9v+I8lrgENtrxwilyRpWpK8Bfgwzy4TuaPtw8OlktaPg5okSZIk7TBufZRGJslrmW0xeQPwd+DHbY8Mm0qSNHVJ7mr7waFzSOvCQU0akSQHgH3AjcBdwFnAoSQ3Ar9p+8yQ+SRJ6y3JO7e6BLxji2uSXgC3PkojkWQf8PH56wrgpfNLpwIfBX4EHG175zAJJUnrLsl/gHuYDWabvaftqSuOJK0tV9Sk8TgAfLJtk1wInAv8EvgA8Dvgp8BtgIOaJGlZHgGubvvnzReS/O05Pi/pBbLSWxqPs9oem79/L/CRtt8BLgcubvtP4NWDpZMkTcF1bP378TMrzCGtPQc1aTyOJzlz/v5fwP4kLwH2A/9OchpwfLB0kqS11/Ynbf+0xbWfrTqPtM68R00aiSSfAt7a9uB8YPsi8GbgUeCrwNXA422/NWBMSdIE2EAsLZ+DmjQSSQLcCvwV+Erb4/PzLwOuAd4GXF6/1JKkJdrUQHyEWQPxwfmxDcTSgjioSSOT5BPAlcCLgGeAMmt8/L5DmiRpmWwgllbHQU2SJEknJclhZg3Ex5Ic4tkNxEeAG4Db2l4yYExpLTioSSOR5ODzXW/79VVlkSRNU5KH2l4wf38fs9bhzrfn39v2oiS/b/v2YZNK4+dz1KTx2DV0AEnS5B1Pcub8kTAbDcSHgUuxgVhaKFfUJEmSdFJsIJZWx0FNGokk33i+620PrCqLJGmabCCWVsetj9J4PDB0AEnStM0HsI/NG4h/nmRzA/F1DmnSYriiJkmSJEk7jCtq0sgk2cNse8n5nHh+DW3fP1goSdIk2EAsrc4pQweQtG23Ao8A5wDXM7tP4P4hA0mSJmPX/3lJWhC3Pkojk+SBtu9K8oe2e+fn7m/77qGzSZIkaTHc+iiNz9Pzv8eS7AOOArsHzCNJmggbiKXVcVCTxudLSV4JfA74JvAK4LPDRpIkTYQNxNKKuPVRkiRJknYYy0SkkUlyS5LT/+f4jCQ/GDKTJGlakuxJ8rUkv0hy98Zr6FzSOnFQk8Znb9snNg7aPg5cMGAeSdL02EAsLZmDmjQ+pyQ5Y+MgyW6831SStFqvansT8HTbe9peBfg8T2mB/HEnjc8NwG+T3D4/vgL48oB5JEnTYwOxtGSWiUgjlOR8Tvzn8u62Dw+ZR5I0LUn2A/cCr+NEA/H1be8YNJi0RhzUpBFKchHwxrY3J9kDvLztX4bOJUmSpMXwHjVpZJJcC1wDfGF+6sXAD4dLJEmaGhuIpeVzUJPG5zLgQ8CTAG2PArsGTSRJmhobiKUlc1CTxuepzvYsFyDJaQPnkSRNjw3E0pL5hZJGJEmAO5N8Fzg9yaeBq4DvDZtMkjQxNhBLS2aZiDQySf4IHAQuAQIcbvurYVNJkqbGBmJpuVxRk8bnQeCJtp8fOogkadJ2A09uNBAnOccGYmlxXFGTRibJo8C5wGPMC0UA2u4dLJQkaVLmDcQXAue1fVOSs4Hb275v4GjS2nBFTRqfS4cOIEmavMuYtTw+CLMG4iQ2EEsL5KAmjUzbx4bOIEmavKfaNokNxNKSWM8vSZKkk7ZFA/GvsYFYWijvUZMkSdK22EAsLZ9bHyVJkrRdNhBLS+aKmiRJkrbFBmJp+RzUJEmStC1JXv9c5y28khbHQU2SJEmSdhhbHyVJkiRph3FQkyRJkqQdxkFNkiRJknYYBzVJkiRJ2mEc1CRJkiRph/kvkvUWcNnzPPoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}