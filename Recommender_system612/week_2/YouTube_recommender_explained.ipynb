{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YouTube_recommender_explained.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IyLhlrX3OIw",
        "colab_type": "text"
      },
      "source": [
        "# YouTube recommender system\n",
        "\n",
        "## System overview\n",
        "\n",
        "YouTube recommender system considered one of the best recommenders in the industry today. YouTube is now owned by Google who is obsessed by deep learning; YouTube is gone with the deep learning to power its recommendations. They published a paper on [Deep Neural Networks for YouTube Recommendations](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf) and they made it available for free for anyone to explore and study. \n",
        "\n",
        "The paper gave a valuable information for the youtubers to optimize their own channel.\n",
        "\n",
        "## The first step - Define the problem\n",
        "\n",
        "YouTube defined their business problem as the following:\n",
        "\n",
        "\n",
        "1.   **Scale**: have ove 1 billion users, who watch more than 5 billion videos every day. \n",
        "2.   **Freshness**: over 500 hours of videos are uploaded to YouTube every minute, and their recommendations must take into account. \n",
        "3.   **Noise**: most of the interest data consists of implicit ratings, not explicit ratings. Which mean that the rating data basing recommendations on which videos people click on. In addition to that, most of the data is also extremely sparse, and the content attributes associated  with their videos is poorly structured.\n",
        "\n",
        "## What did Google do to beat the challenges\n",
        "\n",
        "In 2016 YouTube moved its recommendations to deep learning framework, powered by TesnsorFlow. Before that, their approach was based on matrix factorization. They implemented matrix factorization using neural network.\n",
        "\n",
        "## YouTube deep learning architecture\n",
        "\n",
        "It is interesting that although YouTube has explicit ratings in the form of thumbs up/down ratings, they don't use them at all for generating the recommendations because that data is too sparse. Instead, they depend on implicit signals, such as which videos you actually watched, and what type of videos you searched for. However, these data itself is already sparse; and dealing with such sparsity is a huge issue when trying to apply deep learning to recommender system. \n",
        "\n",
        "Their solution was to break up the sparse representation of vidos Ids and search tokens for each user into a variable-length sequence of sparse data mapped to a dense layer of a fixed length. This makes it easer for input to the neural network in an embedding layer.\n",
        "\n",
        "In simple words, they split up each user's sparse behavior data into chunks of a fixed length. Then take the average of each chunk to reduce that data into fixed-length embedding layer that  can be used as input to the neural network. \n",
        "\n",
        "They restricted this embedding to the most popular videos or search items in order to keep it manageable for the scale prespective. Other obsecure videos you watched mapped to a value of zero. This may seem an arbitrary choice, but they experimented with other ways of doing it including summing and taking the maximum value for each component. The way the embeddings work is itself learned through gradient descent backpropagation, so the system  is actually learning the best way. In this way, they avoided the issue of only training the system on videos or search tokens that were actually invoked by any individual user.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-zBSFLNCRB2",
        "colab_type": "text"
      },
      "source": [
        "At the next layer, they combine together those averaged video watch vectors and search token vectors with any other training features they want to incorporate into their model, such as the user's geographic location, their age, their gender,and presumably other features not shown here. All of those concatenated features are then fed as input into a deep neural network, trained with softmax.\n",
        "\n",
        "This gave them a good balance of accuracy, while staying within their budget for computing hardware.The output of all this is fed into a database of nearest neighbors for each video, to generate more recommendation candidates,based on what the deep neural network found. The problem is then to optimally rank all of these candidates.\n",
        "\n",
        "YouTube also uses deep learning to rank their recommendation candidates to produce a final top-N set of recommendations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzioJWttIgpw",
        "colab_type": "text"
      },
      "source": [
        "## Learning to Rank\n",
        "\n",
        "The output of all this is actually used to predict the expected watch time of each video, which is ultimately what the ranking depends on. They don't want to optimize on predicting just clicks on a video, because this tends to surface clickbait videos that people aren't actually interested in. If a user watches a video all the way through; however, that's a stronger indication of it satisfying that individual's interests. YouTube is optimizing for minutes watched, not for clicks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVWXtAMlKqKL",
        "colab_type": "text"
      },
      "source": [
        "# Attacks on Recommender System\n",
        "\n",
        "Commonly, there are two types of attack: product push and product nuke, which is aim to promote or demote the predictions for targeted items respectively. The inserted data will comprise faked user, selected items, and related ratings. As mentioned in the reference, the selection of items could be done in three strategies; population attack strategy, probe attack strategy, and rating strategy. The first strategy is to choose popular items as it is cheap and easy to get high similarities. The second strategy is to use recommendations as mean to filter items. There are high similarities between genuine and attack profiles as attacker mimic the real distribution of ratings. The third strategy is to manipulate the ratings by assigning the minimum ratings to the disliked items, ratings to liked items, and maximum ratings to the targeted item in a push attack, for example.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4TELjIZMQ-O",
        "colab_type": "text"
      },
      "source": [
        "## Protecting the recommendation systems\n",
        "\n",
        "It has been shown that not only the collaborative recommender systems but also the content-based algorithm, which was thought to be relatively tough, are vulnerable to the reduced-knowledge attack. But using model-based or hybrid algorithms combining collaborative recommendation and other types of recommendation algorithm could effectively make the system more defensive to attack. Model-based or hybrid algorithms have comparable accuracy with that of collaborative approaches. More importantly, they can increase the profile insertion costs.\n",
        "\n",
        "Monitoring the recommender systems and detecting the attack is also very important to prevent the system subversion and to keep the systems healthy. Statistical methods could be used to detect the attack, including detecting the groups of users who push or nuke items, monitoring the development of ratings for an item, and using machine-learning methods to discriminate real from fake profiles. Obfuscate ratings by applying random data perturbation to prevent the hacker to approximate the real data, distributing knowledge to many places, distributing collaborative filtering with estimated concordance measures other than standard similarity measure, and building community to exclude the outsider users are ideas to protect recommender system from attacking.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idiY5giDMdlJ",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "\n",
        "\n",
        "1. Deep Neural Networks for YouTube Recommendations, Paul Covington, Jay Adams, Emre Sargin, Google, Mountain View, CA\n",
        "\n",
        "2. Shyong (Tony) K. Lam. John Riedl. GroupLens Research. Computer Science and Engineering. 2004. Shilling Recommender Systems for Fun and Profit.\n",
        "\n",
        "3. Michael P. O'Mahony and Neil J. Hurley and Gu´enol´e C.M. Silvestr. 2005, American Association for Artificial Intelligence.Recommender Systems: Attack Types and Strategies."
      ]
    }
  ]
}