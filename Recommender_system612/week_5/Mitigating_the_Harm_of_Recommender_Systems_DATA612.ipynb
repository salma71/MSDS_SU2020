{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mitigating the Harm of Recommender Systems_DATA612.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg4X3OwbK_BF",
        "colab_type": "text"
      },
      "source": [
        "## how to counter the radicalizing effects of recommender systems or ways to prevent algorithmic discrimination.\n",
        "\n",
        "Machine learning systems are already being used to make\n",
        "life-changing decisions: which job applicants are hired,\n",
        "which mortgage applicants are given a loan, which prisoners\n",
        "are released on parole. Such decisions affect human rights,\n",
        "often of the most vulnerable people in society.\n",
        "Designed and used well, machine learning systems can help\n",
        "to eliminate the kind of human bias in decision-making that\n",
        "society has been working hard to stamp out. However, it\n",
        "is also possible for machine learning systems to reinforce\n",
        "systemic bias and discrimination and prevent dignity\n",
        "assurance. For example, historical data on employment may\n",
        "show women getting promoted less than men. If a machine\n",
        "learning system trained on such data concludes that women\n",
        "are worse hires, it will perpetuate discrimination.\n",
        "Discriminatory outcomes not only violate human rights, they\n",
        "also undermine public trust in machine learning. If public\n",
        "opinion becomes negative, it is likely to lead to reactive\n",
        "regulations that thwart the development of machine learning\n",
        "and its positive social and economic potential. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RgUi6xTLPsV",
        "colab_type": "text"
      },
      "source": [
        "## The challenges\n",
        "\n",
        "While algorithmic decision-making aids have been used\n",
        "for decades, machine learning is posing new challenges\n",
        "due to its greater complexity, opaqueness, ubiquity, and\n",
        "exclusiveness.\n",
        "Some challenges are related to the data used by machine\n",
        "learning systems. The large datasets needed to train these\n",
        "systems are expensive either to collect or purchase, which\n",
        "effectively excludes many companies, public and civil\n",
        "society bodies from the machine learning market. Training\n",
        "data may exclude classes of individual who do not generate\n",
        "much data, such as those living in rural areas of low-income\n",
        "countries, or those who have opted out of sharing their\n",
        "data. Data may be biased or error-ridden.\n",
        "Even if machine learning algorithms are trained on good\n",
        "data sets, their design or deployment could encode\n",
        "discrimination in other ways: choosing the wrong model\n",
        "(or the wrong data); building a model with inadvertently\n",
        "discriminatory features; absence of human oversight and\n",
        "involvement; unpredictable and inscrutable systems; or\n",
        "unchecked and intentional discrimination."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOSwoijqLZwp",
        "colab_type": "text"
      },
      "source": [
        "## The responsibilities of business\n",
        "\n",
        "Governments and international organizations have a\n",
        "role to play, but regulations tend not to keep pace with\n",
        "technological development. This white paper makes the\n",
        "case that businesses need to integrate principles of nondiscrimination and empathy into their human rights due\n",
        "diligence – a process by which businesses take ongoing,\n",
        "proactive, and reactive steps to ensure that they do not\n",
        "cause or contribute to human rights abuses.\n",
        "Under international human rights law, all companies\n",
        "should respect human rights. According to the UN Guiding\n",
        "Principles on Business and Human Rights, the responsibility\n",
        "to respect human rights “exists over and above compliance\n",
        "with national laws and regulations protecting human rights.”\n",
        "That is, even if there is a lack of regulation specifically about\n",
        "machine learning, human rights principles and obligations\n",
        "still apply. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv_lyisNLh5q",
        "colab_type": "text"
      },
      "source": [
        "## References:\n",
        "\n",
        "  - [How to Prevent\n",
        "Discriminatory Outcomes\n",
        "in Machine Learning - World Economic Forum](http://www3.weforum.org/docs/WEF_40065_White_Paper_How_to_Prevent_Discriminatory_Outcomes_in_Machine_Learning.pdf)"
      ]
    }
  ]
}